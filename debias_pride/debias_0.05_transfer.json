[
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 3.139875502499751,
    "acc": 30.237707587105177,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 7.906799198711612,
    "acc": 31.28622598502117,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 3.154179328136633,
    "acc": 42.85900358189515,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 2.078476236901275,
    "acc": 46.590687072614784,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 5.49128174855242,
    "acc": 33.331162487788994,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 1.6649641203174361,
    "acc": 41.80397264734614,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 6.813471574537272,
    "acc": 53.656789319439916,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 6.216278871276573,
    "acc": 36.40507977857375,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.8113100535447275,
    "acc": 42.53988928687725,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 8.476532046841172,
    "acc": 49.8599804623901,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 4.322980297800884,
    "acc": 37.56431129925106,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 2.2166849524630208,
    "acc": 39.92184956040378,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 6.010035246196682,
    "acc": 45.17095408661673,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 4.930122600902876,
    "acc": 38.52816672093781,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.644853636562386,
    "acc": 44.6304135460762,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 4.640340010870183,
    "acc": 27.697818300227944,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 3.5425450772145552,
    "acc": 41.10713122761315,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 6.122242696167288,
    "acc": 28.16020840117226,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 1.7209421271975571,
    "acc": 40.9833930315858,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 3.23799039891177,
    "acc": 55.4141524958859,
    "cost": 1.1415249588590235
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 3.7978523169887155,
    "acc": 30.09443178117877,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 3.5674136514714676,
    "acc": 37.955063497232175,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 6.310225002480938,
    "acc": 46.68837512211006,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 2.681177914992928,
    "acc": 51.95050472158906,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 4.502018424780337,
    "acc": 37.21263432106805,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 2.1090301173676393,
    "acc": 43.56887007489418,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 3.5116241824597054,
    "acc": 57.12797134483882,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.013816647313801,
    "acc": 38.31976554868122,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 5.690210799536734,
    "acc": 43.992184956040376,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.662001641205199,
    "acc": 53.16183653533051,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 3.0434500355888483,
    "acc": 38.35884076847932,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 1.8506174962168855,
    "acc": 41.777922500814064,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 5.266920986400185,
    "acc": 46.60371214588082,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 5.042007898575754,
    "acc": 40.16281341582546,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 5.710439467474663,
    "acc": 44.84532725496581,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 8.110944990066185,
    "acc": 29.697167046564637,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 5.531438843800546,
    "acc": 44.67600130250732,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 4.126463081597453,
    "acc": 28.244871377401495,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 3.723669982325988,
    "acc": 43.425594268967764,
    "cost": 1.1426245522631064
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 5.331625105852392,
    "acc": 59.626988480526606,
    "cost": 1.1415249588590235
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 19.82394245886755,
    "acc": 34.52517527087316,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 4.435273136281894,
    "acc": 43.58189929891651,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 2.0088336104025863,
    "acc": 62.2880815806246,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 1.6873814536882452,
    "acc": 67.17017208413003,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 10.816520214669564,
    "acc": 42.97641810070108,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 3.762941564836183,
    "acc": 58.897386870618234,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 1.3739092416169472,
    "acc": 75.07966857871256,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 3.4016003138520974,
    "acc": 52.753346080305924,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.729065526040017,
    "acc": 61.65073295092416,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.378998462531312,
    "acc": 70.36966220522626,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 2.5554399460817545,
    "acc": 51.51688973868706,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.52097490637585,
    "acc": 58.126195028680684,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.137820628646338,
    "acc": 67.10006373486297,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 0.8295788547562845,
    "acc": 55.94646271510517,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.5819027266543366,
    "acc": 63.046526449968134,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 13.592610710160297,
    "acc": 28.432122370936895,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 3.2810754209110486,
    "acc": 59.12045889101338,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 6.766903732114801,
    "acc": 27.52708731676227,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 1.938925788207913,
    "acc": 59.05035054174633,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 2.3722683432110143,
    "acc": 75.667215815486,
    "cost": 1.2125205930807248
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 11.064248547986747,
    "acc": 37.597195666029315,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 9.238120454882985,
    "acc": 48.11982154238368,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 4.089700266000588,
    "acc": 66.64117272147864,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 2.9082152195908546,
    "acc": 71.96940726577438,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 6.77737958369589,
    "acc": 51.23008285532186,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 2.9518308916014706,
    "acc": 62.390057361376684,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 2.9272434495562285,
    "acc": 79.29254302103251,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 3.504272374105478,
    "acc": 53.93244104525176,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.199669441197289,
    "acc": 62.294455066921614,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 3.4050622014933536,
    "acc": 73.83683875079669,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 5.555283539642575,
    "acc": 53.01465901848311,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 1.2408797532641116,
    "acc": 60.62460165710644,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 2.519243617178128,
    "acc": 68.7061822817081,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 0.9000442538169959,
    "acc": 58.54684512428298,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 2.261111988375389,
    "acc": 64.09815168897386,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 19.925368219395043,
    "acc": 31.905672402804335,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 3.128176308479599,
    "acc": 64.80560866794137,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 14.964052101593992,
    "acc": 30.796685787125558,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 4.304306270533153,
    "acc": 63.10388782664118,
    "cost": 1.1395793499043978
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 1.7161288553831984,
    "acc": 77.79242174629324,
    "cost": 1.2125205930807248
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 27.582484421605407,
    "acc": 32.40588489831242,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 6.240402127590329,
    "acc": 35.512765036780614,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 7.745444807713246,
    "acc": 49.97403721332756,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 9.15845000681679,
    "acc": 55.18390307226309,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 3.2724848879554287,
    "acc": 38.273474686282995,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 11.966188227731484,
    "acc": 47.265253137170056,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 8.029060613316362,
    "acc": 58.6542622241454,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 11.546821502376371,
    "acc": 42.7260926006058,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 10.239140927615034,
    "acc": 49.10428385980096,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 13.892363338117283,
    "acc": 55.369969710082216,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 7.508753945476407,
    "acc": 44.19299004759844,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 8.83980320681915,
    "acc": 47.47295543054955,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 11.44939536137046,
    "acc": 53.22803980960623,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 10.781377252200873,
    "acc": 45.625270445694504,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 6.180107297528297,
    "acc": 51.51449588922545,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 8.894726840263159,
    "acc": 26.538295110341842,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 11.709214108631327,
    "acc": 48.64128083080917,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 6.339023576620596,
    "acc": 26.68109043704024,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 10.350414354390175,
    "acc": 47.22198182604932,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 5.279668959435599,
    "acc": 74.01883830455259,
    "cost": 1.2025117739403455
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 17.570916274769875,
    "acc": 33.27131112072696,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 11.256757220082438,
    "acc": 43.154478580700996,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 6.257392402467366,
    "acc": 56.404154045867585,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 1.9977427298935004,
    "acc": 61.66161834703591,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 5.64358269412363,
    "acc": 42.99004759844224,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 5.120669195014047,
    "acc": 51.33275638251839,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 3.401434739194829,
    "acc": 64.12375594980529,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 6.508742569847627,
    "acc": 43.15015144958892,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.069193488820335,
    "acc": 50.913024664647345,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 5.547043931549192,
    "acc": 59.08697533535267,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 11.676367790880777,
    "acc": 43.11120726958027,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 6.703953756502415,
    "acc": 49.190826482042404,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 2.823952750742643,
    "acc": 56.49069666810904,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 7.759489831401088,
    "acc": 46.391172652531374,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 7.059759731666506,
    "acc": 53.020337516226746,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 5.850422629367507,
    "acc": 27.217654694937256,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 7.950077288875012,
    "acc": 51.87364777152747,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 14.430025389257114,
    "acc": 27.304197317178712,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 6.320978174874779,
    "acc": 49.51536131544786,
    "cost": 1.094764171354392
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 1.4264822007840614,
    "acc": 75.49450549450549,
    "cost": 1.2025117739403455
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 11.261469700360376,
    "acc": 37.8355754857997,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 19.259335560453707,
    "acc": 35.05530642750374,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 4.343538474499201,
    "acc": 59.784753363228695,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 1.3321985171151822,
    "acc": 63.97010463378176,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 16.45985949146084,
    "acc": 42.648729446935725,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 5.314641119081146,
    "acc": 57.45889387144992,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 1.0928100916522272,
    "acc": 69.73991031390135,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 2.134523372962522,
    "acc": 53.25560538116592,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.667914312227326,
    "acc": 60.38863976083708,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 3.500797304437133,
    "acc": 65.7339312406577,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 3.277688406803814,
    "acc": 52.322869955156946,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.185523010573755,
    "acc": 56.09566517189835,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 4.516937683184695,
    "acc": 63.12705530642749,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 3.0687227628713374,
    "acc": 55.34828101644244,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 1.1309335166626022,
    "acc": 60.69357249626309,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 9.854224229824402,
    "acc": 27.228699551569502,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 5.48106554138794,
    "acc": 58.66068759342303,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 7.76097339703148,
    "acc": 29.327354260089685,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 3.2138402906117634,
    "acc": 59.08520179372198,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 3.633237789383938,
    "acc": 69.94528043775651,
    "cost": 1.1764705882352942
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 10.721475442042829,
    "acc": 38.45142002989537,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 3.406558901997612,
    "acc": 53.29745889387145,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 4.633469243407161,
    "acc": 63.994020926756356,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 2.901991337831878,
    "acc": 66.60089686098654,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 5.949883681828315,
    "acc": 51.473841554559044,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 1.5800599434378584,
    "acc": 61.33931240657698,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 0.7535728617281061,
    "acc": 73.37518684603887,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 2.950338386755525,
    "acc": 53.15994020926756,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.011910904105293,
    "acc": 60.137518684603876,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 2.3423676984406625,
    "acc": 67.44992526158445,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 1.7357806322434097,
    "acc": 52.37668161434978,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 2.3440370402926853,
    "acc": 57.548579970104626,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 5.429849434530662,
    "acc": 63.61136023916292,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 4.7106870291076515,
    "acc": 56.926756352765324,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.020474186505866,
    "acc": 61.66816143497757,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 10.874843849654885,
    "acc": 30.953662182361732,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 1.8064266656536774,
    "acc": 62.88789237668161,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 11.072288740003444,
    "acc": 30.72645739910314,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 1.3114460772025829,
    "acc": 61.75186846038864,
    "cost": 1.1309417040358745
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 3.788105718007813,
    "acc": 72.95485636114911,
    "cost": 1.1764705882352942
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 4.28301257624349,
    "acc": 39.115179252479024,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 10.441505297819939,
    "acc": 48.421052631578945,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 0.9957494397352606,
    "acc": 65.2326468344775,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 4.527323139521006,
    "acc": 70.4042715484363,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 13.866858220034738,
    "acc": 41.49504195270786,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 5.43356317763138,
    "acc": 60.991609458428684,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 3.0171113367036853,
    "acc": 78.09305873379101,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.393096959977339,
    "acc": 55.774218154080856,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.3824358383752555,
    "acc": 63.630816170861934,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 5.079959984691004,
    "acc": 75.20976353928299,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 6.795202473975321,
    "acc": 51.472158657513354,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.736031718509416,
    "acc": 62.05949656750572,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 2.2147543174009305,
    "acc": 70.48054919908466,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 3.5092460425901613,
    "acc": 56.8421052631579,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.6565895538227755,
    "acc": 67.07856598016781,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 12.927148596192202,
    "acc": 28.222730739893212,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 4.4421373005024565,
    "acc": 60.94584286803966,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 7.657785911720367,
    "acc": 27.871853546910756,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 4.5996725869747666,
    "acc": 60.1067887109077,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 0,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 1.7654721326680263,
    "acc": 82.86629303442753,
    "cost": 1.2065652522017614
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 13.444265681008753,
    "acc": 38.077803203661325,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 6.306661284026856,
    "acc": 53.92829900839054,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 1.2939786615571305,
    "acc": 70.22120518688024,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 1.8579853253761562,
    "acc": 75.46910755148741,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 6.159651886967367,
    "acc": 54.23340961098398,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 2.4297983242309975,
    "acc": 64.40884820747522,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 1.193758213922109,
    "acc": 81.2509534706331,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 2.9824722430180333,
    "acc": 56.00305110602593,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.436326843837815,
    "acc": 65.99542334096108,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 3.5442027682862958,
    "acc": 78.07780320366132,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 5.604102818994019,
    "acc": 55.57589626239512,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 3.7523625688131426,
    "acc": 63.325705568268496,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 2.448666314884094,
    "acc": 71.9298245614035,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 3.386558120226322,
    "acc": 60.27459954233409,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 2.3146166042718663,
    "acc": 68.60411899313502,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 19.08161711788303,
    "acc": 30.38901601830663,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 3.306623326346743,
    "acc": 67.53623188405797,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 15.914044161835239,
    "acc": 29.122807017543856,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 3.403795962893709,
    "acc": 66.04118993135012,
    "cost": 1.334096109839817
  },
  {
    "num_shots": 5,
    "source_task": "STEM",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 1.6281844776244772,
    "acc": 84.59567654123299,
    "cost": 1.2065652522017614
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 9.903822160846142,
    "acc": 31.424853610930388,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 11.812602887028063,
    "acc": 31.80871828236825,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 6.0951668038892475,
    "acc": 43.519843851659076,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 1.8119024548413971,
    "acc": 47.553675992192574,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 8.800833984651257,
    "acc": 34.46324007807417,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 2.85738600588887,
    "acc": 42.49837345478204,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 14.045928461746048,
    "acc": 54.502277163305145,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 14.298682012450575,
    "acc": 38.217306441119064,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 11.139942377727401,
    "acc": 43.29212752114508,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 13.307722117272675,
    "acc": 50.396877033181525,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 4.987796817951756,
    "acc": 38.42550422901756,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 2.131495750926816,
    "acc": 40.73519843851659,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 9.722647904987952,
    "acc": 46.49967469095641,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 9.97213237754379,
    "acc": 39.59011060507483,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 6.345076820132164,
    "acc": 45.24398178269356,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 14.811430829019477,
    "acc": 27.31294729993494,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 6.933156451539591,
    "acc": 41.99089134677944,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 10.784590480124471,
    "acc": 29.056603773584904,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 4.5694725548018145,
    "acc": 42.160052049446975,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 3.7821752843687078,
    "acc": 56.24093697713329,
    "cost": 1.093697713329615
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 15.477437377332228,
    "acc": 31.001951854261545,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 8.029376659962928,
    "acc": 38.301886792452834,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 8.210665594429582,
    "acc": 47.17631750162655,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 10.482784360049152,
    "acc": 51.22966818477554,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 14.247308118364737,
    "acc": 36.55172413793103,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 5.346093802793295,
    "acc": 43.76057254391672,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 9.37983546830502,
    "acc": 58.52960312296682,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 10.016098860556447,
    "acc": 39.1476903057905,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 10.149839427875248,
    "acc": 44.30709173715029,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 9.223003598324665,
    "acc": 53.630448926480156,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 9.342931787380033,
    "acc": 38.41899804814574,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.692192391590072,
    "acc": 42.121014964216,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 8.261855522693379,
    "acc": 47.06571242680546,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 10.160213899704905,
    "acc": 41.229668184775534,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 10.677345605499365,
    "acc": 44.50878334417697,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 11.568132770364988,
    "acc": 29.817826935588812,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 12.237719442571564,
    "acc": 45.41314248536109,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 15.349687685790247,
    "acc": 27.130774235523752,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 7.521635971263491,
    "acc": 43.285621340273266,
    "cost": 1.145413142485361
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 9.292084862990285,
    "acc": 60.45733407696598,
    "cost": 1.093697713329615
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 3.9477472764866826,
    "acc": 38.44635466411971,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 3.8914398701056685,
    "acc": 44.86469277300223,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 4.070949964433328,
    "acc": 63.151862464183374,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 1.440495381434556,
    "acc": 68.27761859280483,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 5.927464243705806,
    "acc": 44.55269022604266,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 2.4580898630915704,
    "acc": 59.87901942056669,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 3.228424353391469,
    "acc": 75.6701687360713,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.389887219923177,
    "acc": 53.0722699777141,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.11947587754411,
    "acc": 62.33046800382044,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 6.23644161742677,
    "acc": 71.25756128621458,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 1.8987713486966649,
    "acc": 52.41006049028972,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.371401456252956,
    "acc": 59.01305316778096,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 4.231489456192219,
    "acc": 68.11843361986628,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 3.2915236367619256,
    "acc": 56.21776504297994,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 2.653349847604549,
    "acc": 63.807704552690225,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 4.727961250903305,
    "acc": 26.927730022285896,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 3.9596003044323154,
    "acc": 59.97453040432983,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 10.163702775346348,
    "acc": 27.749124482648842,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 2.1406950979087163,
    "acc": 60.31200254695956,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 2.7047802718914395,
    "acc": 76.99324324324324,
    "cost": 1.1418918918918919
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 5.532513672934287,
    "acc": 38.847500795924866,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 6.77792904215246,
    "acc": 48.71696911811525,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 4.2767485636786144,
    "acc": 67.22063037249283,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 2.4652433240017912,
    "acc": 72.46099968163006,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 5.992385207344214,
    "acc": 52.308182107609035,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 1.493278037050117,
    "acc": 62.712511938872964,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 2.7932392085392985,
    "acc": 80.35657433938236,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.231680565885848,
    "acc": 54.212034383954155,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 5.230614993516452,
    "acc": 62.91626870423431,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 3.361179015866127,
    "acc": 74.60044571792423,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 2.52692612840639,
    "acc": 54.22476918178925,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 2.884287091543449,
    "acc": 61.24164278892073,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.70938524237751,
    "acc": 69.27730022285895,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 2.6839332167491667,
    "acc": 58.917542184017826,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 4.347186955338207,
    "acc": 64.16427889207259,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 9.022257463290165,
    "acc": 31.645972620184654,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 3.4827656957623363,
    "acc": 65.48869786692137,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 5.013392318312837,
    "acc": 29.563833174148357,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 2.7776725044756683,
    "acc": 63.51480420248329,
    "cost": 1.1423113658070678
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 1.5929179982308828,
    "acc": 78.86824324324324,
    "cost": 1.1418918918918919
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 13.55367442115776,
    "acc": 34.01513513513513,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 9.853380546294972,
    "acc": 36.43675675675675,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 9.000866959892294,
    "acc": 50.590270270270274,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 8.8933656056907,
    "acc": 55.96972972972973,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 6.85617893121704,
    "acc": 38.53405405405405,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 7.664717658869288,
    "acc": 47.9827027027027,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 10.270087823343767,
    "acc": 60.07351351351351,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 15.990449704698705,
    "acc": 43.26486486486486,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 14.590794690941493,
    "acc": 49.88972972972973,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 16.441912455682083,
    "acc": 55.541621621621616,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 9.866886072137461,
    "acc": 44.70918918918919,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 8.907772470477287,
    "acc": 48.012972972972975,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 13.142940657017007,
    "acc": 53.94162162162162,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 12.30100600945916,
    "acc": 46.14918918918919,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 4.652743532690307,
    "acc": 51.965405405405406,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 13.329741718210766,
    "acc": 25.699459459459455,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 12.101396250743552,
    "acc": 49.47891891891892,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 9.461967761088696,
    "acc": 26.815135135135137,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 7.470132770143303,
    "acc": 47.87891891891892,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 6.589245440011385,
    "acc": 74.69453376205789,
    "cost": 1.135048231511254
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 14.45121799417701,
    "acc": 33.02486486486487,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 8.230611935853835,
    "acc": 43.43783783783785,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 8.060151329019364,
    "acc": 56.28108108108108,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 3.16526110993996,
    "acc": 62.24432432432432,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 14.381959046200507,
    "acc": 41.84648648648649,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 8.170360446293905,
    "acc": 51.152432432432434,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 3.3442656231784023,
    "acc": 65.17189189189189,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 9.35888724740082,
    "acc": 43.41621621621621,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 8.659290508285483,
    "acc": 50.61189189189189,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 6.219659155843317,
    "acc": 59.943783783783786,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 9.859366485351373,
    "acc": 43.41621621621621,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 8.34566557752019,
    "acc": 49.17621621621621,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.3005625596171932,
    "acc": 56.96,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 9.832555273971014,
    "acc": 46.91027027027026,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 9.706104332256626,
    "acc": 52.33297297297297,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 9.430218795599503,
    "acc": 27.62810810810811,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 11.700036966061097,
    "acc": 52.185945945945946,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 24.197478612946934,
    "acc": 28.198918918918917,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 7.576116675933522,
    "acc": 50.14054054054054,
    "cost": 1.0966486486486486
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 2.191240301489315,
    "acc": 76.44694533762058,
    "cost": 1.135048231511254
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 7.1684569877289075,
    "acc": 39.02031063321386,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 22.287364243140253,
    "acc": 34.74910394265233,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 5.640538796061156,
    "acc": 60.67502986857826,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 1.0953806947252809,
    "acc": 64.9641577060932,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 10.634715649068053,
    "acc": 44.79689366786141,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 3.228199448320413,
    "acc": 58.70370370370371,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 3.574191091361,
    "acc": 70.58542413381123,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 4.17938808694517,
    "acc": 53.817204301075265,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 7.307134630209299,
    "acc": 60.94982078853046,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 5.517150127023956,
    "acc": 66.35005973715651,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 3.662212036567161,
    "acc": 53.32138590203107,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 3.5362289906535977,
    "acc": 56.99522102747909,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 5.591865225731718,
    "acc": 64.32497013142174,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 4.261871705185529,
    "acc": 56.24850657108722,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 1.4646601772798316,
    "acc": 61.94145758661888,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 3.5214195523830676,
    "acc": 28.225806451612904,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 5.723333015729613,
    "acc": 59.94623655913979,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 9.64899749982872,
    "acc": 29.994026284348866,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 2.4607760594344326,
    "acc": 60.90800477897252,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 3.903640631531993,
    "acc": 70.79608938547486,
    "cost": 1.1173184357541899
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 12.085170310132105,
    "acc": 38.53643966547192,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 6.8614377073340735,
    "acc": 53.79928315412186,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 6.2455983856957,
    "acc": 64.93428912783752,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 5.596525117217564,
    "acc": 67.51493428912784,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 10.674743088877525,
    "acc": 51.84587813620071,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 5.6396658786449345,
    "acc": 61.29629629629629,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 2.321582196170418,
    "acc": 74.52807646356032,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 6.870206680195766,
    "acc": 53.6678614097969,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 7.049795877761342,
    "acc": 60.836320191158904,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.178206403236284,
    "acc": 68.48864994026285,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 4.890735210818012,
    "acc": 53.00477897252091,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.030101594376727,
    "acc": 58.548387096774185,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 7.0050846161106675,
    "acc": 64.6415770609319,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 4.460440644790159,
    "acc": 57.58064516129032,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 6.171960187524997,
    "acc": 61.71445639187574,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 5.932018558343354,
    "acc": 31.606929510155318,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 3.4093642586770523,
    "acc": 64.32497013142174,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 7.5128651573190925,
    "acc": 30.238948626045403,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 2.9060720660700516,
    "acc": 62.45519713261649,
    "cost": 1.1335125448028673
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 4.8303778869578045,
    "acc": 73.85474860335196,
    "cost": 1.1173184357541899
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 13.191724042105847,
    "acc": 40.19786910197869,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 6.4489761610761835,
    "acc": 50.852359208523595,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 2.0456107554001703,
    "acc": 67.06240487062405,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 4.58796668422918,
    "acc": 72.96803652968035,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 9.323086754741652,
    "acc": 44.65753424657534,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 3.9123715512247004,
    "acc": 63.34855403348554,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 4.634237473020876,
    "acc": 80.15220700152207,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 7.091228765931886,
    "acc": 57.64079147640791,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 8.034722104196842,
    "acc": 65.69254185692543,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 6.565045189552781,
    "acc": 77.42770167427702,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 7.178288310672573,
    "acc": 53.85083713850837,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.11334838396462,
    "acc": 63.957382039573815,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.457398568671222,
    "acc": 73.05936073059361,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 5.678008899037236,
    "acc": 58.52359208523592,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.5402091722556768,
    "acc": 69.75646879756468,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 11.439192563106738,
    "acc": 26.43835616438356,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 5.415612702239748,
    "acc": 63.94216133942162,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 7.911529406507052,
    "acc": 28.401826484018265,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 4.2663110105659765,
    "acc": 63.05936073059361,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 0,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 2.2623140132415087,
    "acc": 84.019688269073,
    "cost": 1.1378178835110746
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 24.873849838290386,
    "acc": 38.143074581430746,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 3.387745883928652,
    "acc": 57.26027397260274,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 2.667010824952098,
    "acc": 72.95281582952816,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 4.063003748067685,
    "acc": 76.7579908675799,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 9.466039239693089,
    "acc": 55.99695585996956,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 4.726961863801437,
    "acc": 67.09284627092845,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 1.910894334059817,
    "acc": 83.92694063926942,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.746923501997486,
    "acc": 58.09741248097413,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 5.957664307552145,
    "acc": 67.88432267884323,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.39554738817664,
    "acc": 80.31963470319636,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 8.214178327659251,
    "acc": 57.488584474885855,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.46925580306165,
    "acc": 65.49467275494672,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 2.9754782485352735,
    "acc": 74.53576864535769,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 6.091613330297119,
    "acc": 62.31354642313547,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 5.354302987168786,
    "acc": 70.62404870624049,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 10.566908930661219,
    "acc": 30.045662100456617,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 4.628185664029473,
    "acc": 70.13698630136987,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 21.675646987929163,
    "acc": 29.19330289193303,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 5.38761473483835,
    "acc": 67.62557077625573,
    "cost": 1.3401826484018264
  },
  {
    "num_shots": 5,
    "source_task": "Social Science",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 2.159731720534225,
    "acc": 86.39868744872847,
    "cost": 1.1378178835110746
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 13.94772252363612,
    "acc": 32.30622617534943,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 11.14581261961987,
    "acc": 32.11562897077509,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 4.47341246219342,
    "acc": 43.640406607369755,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 7.2458940414804545,
    "acc": 46.207115628970776,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 9.180092597407484,
    "acc": 33.449809402795424,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 7.005257997960572,
    "acc": 41.912325285895804,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 9.015313654317342,
    "acc": 53.62134688691232,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 10.970864043092647,
    "acc": 37.67471410419314,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 9.184058273078517,
    "acc": 43.03684879288437,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 9.078195819590219,
    "acc": 50.59085133418043,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 5.9572199946494795,
    "acc": 38.06226175349428,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 6.965940460466932,
    "acc": 40.19059720457433,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 6.202607224220049,
    "acc": 46.12452350698857,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 6.945113632401023,
    "acc": 39.18678526048285,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 5.893596325391966,
    "acc": 44.91105463786531,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 4.283716862913228,
    "acc": 27.642947903430745,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 12.767477752886034,
    "acc": 40.946632782719185,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 7.345877713243792,
    "acc": 29.0851334180432,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 5.865947727136592,
    "acc": 41.327827191867854,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 2.857385507709969,
    "acc": 55.99109131403118,
    "cost": 1.0985523385300668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 15.940919975580655,
    "acc": 31.91232528589581,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 8.83018432656755,
    "acc": 38.03684879288437,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 6.664338513197504,
    "acc": 47.00762388818298,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 6.948309256541276,
    "acc": 52.15374841168996,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 12.723859390952144,
    "acc": 36.10546378653113,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 4.13100020101228,
    "acc": 44.16137229987293,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 6.807736006630226,
    "acc": 58.22744599745871,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 6.767821613575579,
    "acc": 38.04320203303685,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.610147277787073,
    "acc": 44.54891994917408,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.729538335306824,
    "acc": 53.608640406607364,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 10.152392891954914,
    "acc": 38.91994917407878,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 2.7033391457879445,
    "acc": 42.05209656925032,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 8.438363117594164,
    "acc": 47.249047013977126,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 10.356207520492202,
    "acc": 39.91105463786531,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 7.758806151432404,
    "acc": 44.99364675984752,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 17.511670422988054,
    "acc": 30.648030495552735,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 8.042397916142122,
    "acc": 44.402795425667094,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 16.354513315858846,
    "acc": 27.388818297331635,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 6.853021258979764,
    "acc": 43.27827191867853,
    "cost": 1.2125158831003813
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 3.2938498664364717,
    "acc": 59.977728285077944,
    "cost": 1.0985523385300668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 8.387442357425552,
    "acc": 39.48367029548989,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 4.276347893776612,
    "acc": 44.24883359253499,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 2.9666022531989986,
    "acc": 62.040435458786945,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 3.6456678902042072,
    "acc": 67.31570762052877,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 13.120517774479941,
    "acc": 42.874027993779166,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 3.39934948275384,
    "acc": 59.850699844479,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 2.0675159614367273,
    "acc": 74.73094867807154,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 3.80716034858735,
    "acc": 52.41057542768274,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.234958032998234,
    "acc": 62.13996889580094,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.04105146580585,
    "acc": 70.4199066874028,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 2.6415645897896747,
    "acc": 51.85692068429239,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 6.115216633698213,
    "acc": 57.51788491446346,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.163665469526855,
    "acc": 67.53965785381027,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 2.3548155981405903,
    "acc": 55.62674961119751,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 2.39005615094597,
    "acc": 63.1353032659409,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 12.104467378364129,
    "acc": 27.732503888024883,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 7.692808743061891,
    "acc": 58.861586314152404,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 6.937523320433516,
    "acc": 27.682737169517885,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 2.3634001190176934,
    "acc": 59.45256609642301,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 2.780885408905984,
    "acc": 76.56276326874475,
    "cost": 1.1491154170176916
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 20.935857635088436,
    "acc": 38.2954898911353,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 8.293797049045477,
    "acc": 48.1741835147745,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 3.6213587835372065,
    "acc": 66.23950233281494,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 1.518569050020371,
    "acc": 72.46656298600311,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 6.46428535336748,
    "acc": 51.45878693623639,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 1.6175541848191728,
    "acc": 62.1710730948678,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 2.8623542705249596,
    "acc": 79.52721617418351,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 3.0817519879297857,
    "acc": 53.83514774494556,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.364968892465962,
    "acc": 62.432348367029554,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 3.0055515005493363,
    "acc": 73.8475894245723,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 7.4565901400970915,
    "acc": 53.399688958009335,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 1.9779901196995968,
    "acc": 60.54743390357699,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.113222859984389,
    "acc": 68.27371695178849,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 2.7394156329451724,
    "acc": 58.05909797822706,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.3553474796057423,
    "acc": 64.03732503888025,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 27.935043296127873,
    "acc": 32.99533437013997,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 3.3846650947137773,
    "acc": 64.58475894245723,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 14.25875166147593,
    "acc": 29.94090202177294,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 4.5064804152736615,
    "acc": 62.89891135303266,
    "cost": 1.2080870917573872
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 1.4543477818130297,
    "acc": 79.2586352148273,
    "cost": 1.1491154170176916
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 4.407718393177774,
    "acc": 33.8497552670781,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 7.019575307007386,
    "acc": 36.118323047456904,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 5.3279499714919,
    "acc": 50.09150883166631,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 7.190442029608012,
    "acc": 55.55224515854438,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 7.617376585104577,
    "acc": 38.518833794424346,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 5.170458340345101,
    "acc": 48.4315811874867,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 8.88663616107846,
    "acc": 58.9955309640349,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 14.49106444417182,
    "acc": 42.85592679293467,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 12.225910156482072,
    "acc": 49.2998510321345,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 14.486103136818263,
    "acc": 55.52245158544372,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 7.443438593595802,
    "acc": 44.20515003192169,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 8.543665998315088,
    "acc": 47.993190040434136,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 11.670294080663108,
    "acc": 53.70504362630347,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 11.10408171400626,
    "acc": 45.75441583315599,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 6.158577817840537,
    "acc": 51.81953607150458,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 7.380851879476222,
    "acc": 26.89082783570973,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 6.989734813619066,
    "acc": 49.40625665035114,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 3.4150417252718257,
    "acc": 27.112151521600346,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 4.503759201381163,
    "acc": 47.001489678655034,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 5.9021961544273225,
    "acc": 74.65918203688854,
    "cost": 1.1419406575781876
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 4.208108032442862,
    "acc": 33.05384124281762,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 9.12714893626011,
    "acc": 42.47286656735476,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 5.576930932371311,
    "acc": 56.49287082357948,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 3.2673343857683177,
    "acc": 62.51542881464142,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 10.010804447927761,
    "acc": 42.89848904022133,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 7.455430063982837,
    "acc": 51.02787827197276,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 2.778346253338497,
    "acc": 64.45626729091296,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 7.9955342909424925,
    "acc": 43.63481591828048,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.858191043899045,
    "acc": 50.981059799957436,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 5.38773303624459,
    "acc": 59.30197914449883,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 4.8225752814169125,
    "acc": 43.51989785060651,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 7.110285842726695,
    "acc": 49.2615450095765,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.979599856320898,
    "acc": 56.795062779314755,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 8.921892102668002,
    "acc": 45.73313470951266,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 7.0639335975553905,
    "acc": 53.0453287933603,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 6.137144192142993,
    "acc": 28.16769525430943,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 6.114506344936536,
    "acc": 51.508831666311984,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 3.748445680969609,
    "acc": 28.17620770376676,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 5.0453376146623,
    "acc": 50.05320280910833,
    "cost": 1.1423707171738668
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 2.2147336963603914,
    "acc": 76.7281475541299,
    "cost": 1.1419406575781876
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 9.051007530436893,
    "acc": 39.21098772647575,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 20.519805166972542,
    "acc": 35.40035067212156,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 4.32735089362524,
    "acc": 59.91817650496786,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 3.7149418681181894,
    "acc": 63.99766218585622,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 17.707639961103105,
    "acc": 42.75277615429574,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 1.7224939021903005,
    "acc": 58.32261835184103,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 2.549299232865831,
    "acc": 69.83050847457628,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 3.4562602992625857,
    "acc": 53.31969608416131,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.6069277835113835,
    "acc": 60.09351256575103,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.068502000278814,
    "acc": 66.05493863237872,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 3.9641239843228275,
    "acc": 52.402104032729405,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 5.6603733976982,
    "acc": 56.24780829924022,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 4.123539397278426,
    "acc": 63.454120397428404,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 5.541937978148809,
    "acc": 55.534774985388665,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 2.791465106867169,
    "acc": 61.279953243717124,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 10.57081334951441,
    "acc": 27.35242548217417,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 8.516621236590588,
    "acc": 58.20572764465226,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 10.146097327330153,
    "acc": 29.98246639392168,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 5.229101965818952,
    "acc": 59.40970192869668,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 3.392493949484769,
    "acc": 70.55052264808361,
    "cost": 1.1233449477351916
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 16.40467585826228,
    "acc": 37.61542957334892,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 7.5774583649296385,
    "acc": 52.7177089421391,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 5.809675167864029,
    "acc": 64.12039742840444,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 2.746791976412819,
    "acc": 67.02513150204558,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 10.088256404925236,
    "acc": 51.215663354763294,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 4.354909890296121,
    "acc": 61.081239041496204,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 1.5426118557523103,
    "acc": 73.96843950905902,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.812647283849809,
    "acc": 53.02746931618937,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.627549302797564,
    "acc": 60.40911747516073,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 2.5951345601318594,
    "acc": 67.510227936879,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 6.655871667502962,
    "acc": 52.606662770309754,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 3.0382002524918468,
    "acc": 57.866744593804796,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 6.66449830997248,
    "acc": 63.73465809468147,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 6.520512104737594,
    "acc": 56.639392168322615,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 4.774110251963825,
    "acc": 61.70660432495616,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 17.296380554961114,
    "acc": 31.642314436002334,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 1.9862571628284251,
    "acc": 62.94564582115722,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 14.765991570376082,
    "acc": 30.04091174751607,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 1.0106375323152914,
    "acc": 61.80596142606663,
    "cost": 1.1954997077732321
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 2.7781012064017063,
    "acc": 74.41114982578397,
    "cost": 1.1233449477351916
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 15.625692319798683,
    "acc": 39.207492795389044,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 8.829123094686377,
    "acc": 49.74063400576369,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 2.195508475003193,
    "acc": 64.68299711815561,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 5.1364418742675895,
    "acc": 70.69164265129685,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 16.41832823044924,
    "acc": 42.680115273775215,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 3.4851143138240297,
    "acc": 61.80115273775216,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 3.843577455288049,
    "acc": 77.57925072046109,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.853467582914869,
    "acc": 55.86455331412104,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 5.3792931523437355,
    "acc": 63.602305475504316,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 5.728346139131302,
    "acc": 75.38904899135446,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 3.590071043603743,
    "acc": 52.766570605187326,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 7.5734453631416185,
    "acc": 60.043227665706056,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.5731994590147442,
    "acc": 71.31123919308358,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 4.930372308694151,
    "acc": 57.29106628242075,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 2.306972830189314,
    "acc": 67.11815561959654,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 11.621866434116509,
    "acc": 28.097982708933717,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 4.027353687272843,
    "acc": 61.700288184438044,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 8.460473360642855,
    "acc": 28.42939481268012,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 3.593288656372244,
    "acc": 61.59942363112391,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 0,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 2.1543291283958665,
    "acc": 84.02618657937808,
    "cost": 1.1448445171849426
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 17.505190705060258,
    "acc": 36.42651296829972,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 7.056911504603603,
    "acc": 54.76945244956772,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 2.0119416346893964,
    "acc": 70.30259365994236,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 3.8181411093461093,
    "acc": 75.18731988472622,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 8.4675733261986,
    "acc": 54.36599423631124,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 4.603354409411496,
    "acc": 65.21613832853026,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 1.4469019481428191,
    "acc": 81.71469740634005,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 3.9601008507501314,
    "acc": 56.512968299711815,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.5484914628625885,
    "acc": 66.44092219020173,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 3.534727224913874,
    "acc": 77.6657060518732,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 4.994990065218152,
    "acc": 55.99423631123919,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 3.7864848018642063,
    "acc": 63.4149855907781,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.5083653027969994,
    "acc": 72.44956772334294,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 5.478771287951997,
    "acc": 59.942363112391924,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.8350403099833117,
    "acc": 68.80403458213257,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 25.137603997260463,
    "acc": 29.034582132564843,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 3.0138083279231442,
    "acc": 66.41210374639769,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 14.890142398327843,
    "acc": 27.86743515850144,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 3.6727813025761167,
    "acc": 65.97982708933718,
    "cost": 1.4819884726224783
  },
  {
    "num_shots": 5,
    "source_task": "Humanities",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 1.4158742149704682,
    "acc": 86.23567921440262,
    "cost": 1.1448445171849426
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 7.684907770823246,
    "acc": 31.73800259403372,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 22.198265898863816,
    "acc": 30.17509727626459,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 5.619266457453275,
    "acc": 43.83268482490272,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 2.530439161528843,
    "acc": 47.80804150453956,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 10.643211039217078,
    "acc": 35.304798962386506,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 4.4494823339761504,
    "acc": 42.69130998702983,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 12.549565465981107,
    "acc": 54.25421530479896,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 14.031728108732986,
    "acc": 37.97665369649805,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 10.405553613918801,
    "acc": 43.242542153047985,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 12.18482579477753,
    "acc": 50.39559014267185,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 5.4351491292929435,
    "acc": 38.3981841763943,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.732839905821889,
    "acc": 40.94682230869002,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 10.51785504212313,
    "acc": 46.42671854734111,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 9.75192704839711,
    "acc": 39.74059662775616,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 5.724978784049277,
    "acc": 45.56420233463035,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 12.61455644444202,
    "acc": 27.619974059662773,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 7.700820470073265,
    "acc": 42.237354085603116,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 16.23188824995064,
    "acc": 27.808041504539556,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 4.5577051564568025,
    "acc": 41.86121919584955,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 2.728422496195265,
    "acc": 55.73407202216066,
    "cost": 1.1130193905817174
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 23.851104091047713,
    "acc": 31.22568093385214,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 10.78797848387587,
    "acc": 38.43060959792477,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 6.490027332401729,
    "acc": 47.7367055771725,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 5.529606922613494,
    "acc": 52.496757457846954,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 9.91546930514291,
    "acc": 37.5875486381323,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 4.439587582640209,
    "acc": 44.22178988326848,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 10.517209219830866,
    "acc": 58.313878080415044,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 10.444622467146921,
    "acc": 39.37743190661479,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 9.17702110590751,
    "acc": 44.474708171206224,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 8.663188144150984,
    "acc": 53.68352788586251,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 7.844534831542812,
    "acc": 38.68352788586252,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 5.234559000152911,
    "acc": 41.91958495460442,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 6.704122648588881,
    "acc": 47.354085603112836,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 9.429780422608797,
    "acc": 41.731517509727624,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 9.463516371972934,
    "acc": 44.87678339818417,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 10.480645997503101,
    "acc": 30.817120622568098,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 11.098330794474204,
    "acc": 45.18158236057069,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 14.495459737245662,
    "acc": 27.561608300907913,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 6.457845620403726,
    "acc": 43.51491569390403,
    "cost": 1.154669260700389
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 4.555275230210582,
    "acc": 59.97783933518006,
    "cost": 1.1130193905817174
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 15.04577388061703,
    "acc": 37.423040304665186,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 16.53859324088169,
    "acc": 39.746112345287216,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 2.691295102319749,
    "acc": 63.0529990479213,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 2.2083254448918987,
    "acc": 68.07997461123452,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 4.375011104933578,
    "acc": 46.10599809584259,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 3.5497253669779205,
    "acc": 60.32370675975879,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 2.825726018562532,
    "acc": 75.5950491907331,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.668193956228606,
    "acc": 52.859409711202794,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 5.7033866254891326,
    "acc": 62.41827991113932,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 5.989346876533987,
    "acc": 71.10758489368455,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 2.0650150008149986,
    "acc": 52.453189463662326,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 5.1952933027182135,
    "acc": 58.68613138686131,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 4.007228087387002,
    "acc": 67.98476674071723,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 2.685674955724586,
    "acc": 56.572516661377335,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.361151996578985,
    "acc": 64.03046651856553,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 11.223441495606938,
    "acc": 28.060933037131072,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 3.345940199124398,
    "acc": 60.07616629641383,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 15.013096036219148,
    "acc": 27.05172960964773,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 2.862013230043459,
    "acc": 60.387178673437006,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 2.2018882498340515,
    "acc": 76.2876254180602,
    "cost": 1.1705685618729098
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 10.350354124733864,
    "acc": 39.84132021580451,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 11.66946066435417,
    "acc": 48.27673754363694,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 2.9097045776705404,
    "acc": 67.60393525864805,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 2.52601986070552,
    "acc": 72.67534116153601,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 2.8899618112264513,
    "acc": 52.62456363059346,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 1.467619813977548,
    "acc": 62.79276420184069,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 3.0429481401369376,
    "acc": 79.94287527768962,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.1455804552276305,
    "acc": 54.43986036178991,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 5.185295570915074,
    "acc": 63.0529990479213,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.215006153860642,
    "acc": 74.38908283084734,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 4.341967126754783,
    "acc": 54.25579181212314,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 2.994478089142786,
    "acc": 60.85687083465566,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 2.626282623192719,
    "acc": 69.38114884163757,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 2.824841451823787,
    "acc": 59.06061567756268,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 4.01934412184496,
    "acc": 64.34782608695653,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 19.253247473046024,
    "acc": 32.40875912408759,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 2.3734821424406127,
    "acc": 65.21739130434783,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 5.811895455522803,
    "acc": 29.450967946683598,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 2.137103594025683,
    "acc": 63.73849571564582,
    "cost": 1.1513805141225009
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 1.5567237589351781,
    "acc": 78.94648829431438,
    "cost": 1.1705685618729098
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 23.59763057846476,
    "acc": 33.09600862998921,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 22.466219113266863,
    "acc": 33.10895361380798,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 9.528518510126078,
    "acc": 50.51995685005394,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 9.653922319923359,
    "acc": 55.81014023732471,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 10.38034428022999,
    "acc": 38.85221143473571,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 7.431430528063591,
    "acc": 48.46601941747573,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 9.518611917868556,
    "acc": 59.81877022653721,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 16.000001613025848,
    "acc": 43.17583603020496,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 13.852766656121222,
    "acc": 49.78209277238403,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 16.03561961903769,
    "acc": 55.46062567421791,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 9.740965591486724,
    "acc": 44.651564185544764,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 8.297397500396707,
    "acc": 48.38834951456311,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 13.567067516917088,
    "acc": 53.83387270765911,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 10.90321320098614,
    "acc": 46.48543689320388,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 5.2466947126151116,
    "acc": 52.254584681769146,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 12.844411275540491,
    "acc": 25.25997842502697,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 11.794737533398145,
    "acc": 49.82092772384035,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 18.66208788135993,
    "acc": 26.08414239482201,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 10.457258404346259,
    "acc": 48.077669902912625,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 6.343724681280618,
    "acc": 74.49044585987261,
    "cost": 1.1624203821656052
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 20.96793023641887,
    "acc": 33.17367853290183,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 17.911877721748233,
    "acc": 42.71844660194175,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 4.965662043115189,
    "acc": 57.11326860841424,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 0.8680355467270837,
    "acc": 62.39913700107875,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 10.352362738846947,
    "acc": 42.58468176914779,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 7.6345472551721185,
    "acc": 51.262135922330096,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 3.0578614200647176,
    "acc": 64.81984897518878,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 9.25613961056011,
    "acc": 43.28802588996764,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 8.013405780319946,
    "acc": 50.97734627831714,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 6.675761152878742,
    "acc": 59.74973031283711,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 8.807627001419496,
    "acc": 43.521035598705495,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 8.978623373468219,
    "acc": 48.988133764832796,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 2.270614447567811,
    "acc": 57.14778856526429,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 10.80155941301026,
    "acc": 46.88241639697951,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 9.185576187238635,
    "acc": 52.62135922330098,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 7.76611864708976,
    "acc": 28.36245954692556,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 9.483103533682584,
    "acc": 52.58683926645092,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 26.332336465031688,
    "acc": 28.25026968716289,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 7.734544246589524,
    "acc": 50.1057173678533,
    "cost": 1.1029126213592233
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 1.592775513328896,
    "acc": 76.76751592356689,
    "cost": 1.1624203821656052
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 5.54956545794707,
    "acc": 39.80345443716497,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 13.412292472052311,
    "acc": 35.902322811197145,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 4.265798448003919,
    "acc": 60.50625372245385,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 0.9259304398149449,
    "acc": 64.79452054794521,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 7.301522228031715,
    "acc": 45.80702799285289,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 3.5688781015778908,
    "acc": 58.898153662894586,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 3.011903408801113,
    "acc": 70.27397260273972,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 4.42480577206574,
    "acc": 53.615247170935085,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.823211285889033,
    "acc": 60.946992257296,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 5.000392860206974,
    "acc": 66.2596783799881,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 4.056491316442385,
    "acc": 53.1328171530673,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.664539140913099,
    "acc": 57.00416914830256,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 6.170922732171784,
    "acc": 64.08576533650982,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 3.1714667637076372,
    "acc": 56.42644431209053,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 1.1778000643690798,
    "acc": 61.86420488385944,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 5.696139310165081,
    "acc": 28.0762358546754,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 4.621894397939309,
    "acc": 60.34544371649791,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 7.892477617800587,
    "acc": 29.809410363311493,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 1.384647257677984,
    "acc": 60.738534842167965,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 3.513362673713658,
    "acc": 70.22160664819945,
    "cost": 1.1412742382271468
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 4.692331090487976,
    "acc": 39.19594997022037,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 5.5088551904754235,
    "acc": 53.25789160214413,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 3.8685976575953482,
    "acc": 64.78260869565217,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 3.9545010495643753,
    "acc": 67.5104228707564,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 6.3400322859135185,
    "acc": 52.4538415723645,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 4.714089301390242,
    "acc": 61.38177486599166,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 2.620173391364294,
    "acc": 74.12150089338893,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 6.089644517848445,
    "acc": 53.811792733770105,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.058635074101805,
    "acc": 60.89338892197736,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.013661165667072,
    "acc": 68.302561048243,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 3.0809710554396,
    "acc": 53.23406789755806,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.310473706864796,
    "acc": 58.1119714115545,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 5.956538163714133,
    "acc": 64.52054794520548,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 4.299960618911498,
    "acc": 57.57593805836808,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 5.69748742566923,
    "acc": 62.054794520547944,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 9.154032798753367,
    "acc": 31.42942227516379,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 2.9153902647757284,
    "acc": 64.02620607504467,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 3.6455158621592885,
    "acc": 30.387135199523527,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 2.929045318064513,
    "acc": 62.53722453841573,
    "cost": 1.1420488385944014
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 2.8471051793631488,
    "acc": 74.34903047091413,
    "cost": 1.1412742382271468
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 12.401740643720666,
    "acc": 39.42598187311178,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 24.352240599171395,
    "acc": 45.740181268882175,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 1.4645523882889162,
    "acc": 66.79758308157099,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 4.323478234855571,
    "acc": 72.46223564954683,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 6.843277354293394,
    "acc": 45.785498489425976,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 3.1164118682356934,
    "acc": 63.76132930513595,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 4.3097432958809065,
    "acc": 79.57703927492447,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 7.107488918366184,
    "acc": 57.175226586102724,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 7.777540207170267,
    "acc": 65.72507552870091,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 6.3262900192421245,
    "acc": 76.94864048338368,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 6.645890045455557,
    "acc": 53.564954682779444,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 5.44002596552406,
    "acc": 63.21752265861028,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.174540251663216,
    "acc": 72.61329305135952,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 5.181648493482392,
    "acc": 58.86706948640483,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.4017523450471443,
    "acc": 69.63746223564955,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 14.262806025384341,
    "acc": 27.583081570996978,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 4.218318579203463,
    "acc": 64.3202416918429,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 6.369206552756629,
    "acc": 28.68580060422961,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 5.075493149371055,
    "acc": 63.096676737160124,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 0,
    "source_task": "Others",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 2.0605576067984326,
    "acc": 83.54183590576767,
    "cost": 1.165718927701056
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 29.4881238896448,
    "acc": 36.1178247734139,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 10.087734583251608,
    "acc": 55.453172205438065,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 2.3367081635559446,
    "acc": 72.59818731117825,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 3.4082503032690212,
    "acc": 77.40181268882176,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 7.296075636674819,
    "acc": 56.48036253776436,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 4.232443964062606,
    "acc": 66.4954682779456,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 2.4546408941366686,
    "acc": 82.9607250755287,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.784388425646268,
    "acc": 58.141993957703924,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 5.764431367336766,
    "acc": 68.1117824773414,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.7046298796968715,
    "acc": 79.80362537764351,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 7.42002369872502,
    "acc": 57.05438066465257,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 5.198282628839985,
    "acc": 64.83383685800604,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 2.647667568177645,
    "acc": 74.03323262839879,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 6.116155566748503,
    "acc": 62.09969788519637,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 4.884509898395933,
    "acc": 70.80060422960726,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 18.976314933878655,
    "acc": 30.619335347432024,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 4.620389584344579,
    "acc": 69.45619335347432,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 24.784603391920648,
    "acc": 29.864048338368583,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 4.8833502139165965,
    "acc": 67.87009063444108,
    "cost": 1.3602719033232629
  },
  {
    "num_shots": 5,
    "source_task": "Others",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 1.5361072844903032,
    "acc": 86.1251015434606,
    "cost": 1.165718927701056
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 6.3664273936599045,
    "acc": 29.694937981897418,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 14.92743285361647,
    "acc": 30.425745893395913,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 9.217180570333502,
    "acc": 42.72879651357694,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 10.528789630394686,
    "acc": 46.81193429433456,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 10.91239344240827,
    "acc": 33.96580623533355,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 4.312072842017996,
    "acc": 42.038216560509554,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 15.789188185943534,
    "acc": 53.590345289976526,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 13.196308826038106,
    "acc": 37.25779416694603,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 11.8418496110052,
    "acc": 43.07743881997989,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 14.725967708248316,
    "acc": 49.81562185719075,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 5.37981949082865,
    "acc": 37.17063359034529,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 3.452873217448844,
    "acc": 40.18102581293999,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 11.621866940310499,
    "acc": 45.71907475695608,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 10.084875099317205,
    "acc": 39.20885015085484,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 6.129505005384087,
    "acc": 44.96144820650352,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 16.281490253315447,
    "acc": 28.159570901776732,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 7.58858256953125,
    "acc": 41.05263157894737,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 19.573016271238544,
    "acc": 27.71706335903453,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 7.620816962337753,
    "acc": 41.253771371102914,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 3.2703691871568195,
    "acc": 56.33426183844011,
    "cost": 1.0969359331476323
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "llama-7b",
    "rstd": 15.658708897178624,
    "acc": 28.481394569225607,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "llama-13b",
    "rstd": 14.167766502065462,
    "acc": 36.48005363727791,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "llama-30b",
    "rstd": 11.920712777664438,
    "acc": 46.356017432115316,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "llama-65b",
    "rstd": 11.36420920111063,
    "acc": 50.55983908816628,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-7b-hf",
    "rstd": 12.238070145034595,
    "acc": 37.20415688903788,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-13b-hf",
    "rstd": 7.143001790923289,
    "acc": 43.747904793831715,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-70b-hf",
    "rstd": 11.265115015170677,
    "acc": 57.184042909822324,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 10.27343629677979,
    "acc": 38.585316795172645,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 5.802306575783901,
    "acc": 44.29098223265169,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 8.362393940771115,
    "acc": 53.06738183037212,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.3",
    "rstd": 4.8415558838131085,
    "acc": 37.72041568890379,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.3",
    "rstd": 12.248515809146664,
    "acc": 40.67046597385182,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-33b-v1.3",
    "rstd": 8.357299483087322,
    "acc": 46.55045256453235,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-7b-v1.5",
    "rstd": 12.679782526708786,
    "acc": 40.20113979215555,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "vicuna-13b-v1.5",
    "rstd": 8.54141970041828,
    "acc": 44.92122024807241,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "falcon-7b",
    "rstd": 14.695920876355956,
    "acc": 28.4411666107945,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "falcon-40b",
    "rstd": 12.632813284950869,
    "acc": 44.50553134428427,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "falcon-7b-instruct",
    "rstd": 24.91255396302922,
    "acc": 26.262152195776064,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "falcon-40b-instruct",
    "rstd": 12.462689328010011,
    "acc": 43.151190077103585,
    "cost": 1.058330539725109
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "STEM",
    "model": "ichat",
    "rstd": 7.184108655086817,
    "acc": 60.434540389972156,
    "cost": 1.0969359331476323
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 23.15795286605158,
    "acc": 33.34426229508197,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 9.956662809911842,
    "acc": 42.675409836065576,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 5.809486612871883,
    "acc": 62.74098360655737,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 6.524983921323717,
    "acc": 68.77377049180329,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 6.951972687028797,
    "acc": 45.049180327868854,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 4.243791738072181,
    "acc": 60.321311475409836,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 4.027455735297257,
    "acc": 75.42295081967212,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.452320100803119,
    "acc": 52.81311475409835,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 6.476825096692545,
    "acc": 62.44590163934426,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 7.208443319874871,
    "acc": 71.15409836065574,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 2.794286751789434,
    "acc": 51.88852459016393,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.6338820468355815,
    "acc": 59.02295081967213,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 4.997314321026623,
    "acc": 68.0327868852459,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 3.136778336079924,
    "acc": 56.61639344262295,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.6497955121984744,
    "acc": 63.98032786885246,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 7.111485452325306,
    "acc": 27.127868852459017,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 4.829351189952483,
    "acc": 59.678688524590164,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 17.667320660437344,
    "acc": 26.852459016393443,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 3.1545254508777805,
    "acc": 60.15737704918033,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 2.3604036676513833,
    "acc": 77.2512647554806,
    "cost": 1.1467116357504217
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "llama-7b",
    "rstd": 22.658747100748503,
    "acc": 34.55081967213115,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "llama-13b",
    "rstd": 10.125342792891166,
    "acc": 47.088524590163935,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "llama-30b",
    "rstd": 5.955334988666771,
    "acc": 67.12131147540984,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "llama-65b",
    "rstd": 4.959454024012018,
    "acc": 72.45245901639345,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-7b-hf",
    "rstd": 3.7092774326137175,
    "acc": 52.55081967213115,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-13b-hf",
    "rstd": 5.198023958376877,
    "acc": 62.911475409836065,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-70b-hf",
    "rstd": 4.074831100514691,
    "acc": 80.22295081967212,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 6.778481245479007,
    "acc": 54.02622950819672,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.619461652317834,
    "acc": 63.25901639344263,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 2.9220092611229007,
    "acc": 74.54426229508196,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.3",
    "rstd": 5.756057457696646,
    "acc": 53.10819672131147,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.3",
    "rstd": 5.319872040741666,
    "acc": 60.334426229508196,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.472493892278648,
    "acc": 69.21967213114755,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-7b-v1.5",
    "rstd": 3.6801951225946494,
    "acc": 58.57704918032787,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "vicuna-13b-v1.5",
    "rstd": 4.103863873874955,
    "acc": 64.64918032786885,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "falcon-7b",
    "rstd": 12.00003660644638,
    "acc": 31.21311475409836,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "falcon-40b",
    "rstd": 5.472438333891896,
    "acc": 65.5606557377049,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "falcon-7b-instruct",
    "rstd": 30.477264732172774,
    "acc": 27.140983606557377,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "falcon-40b-instruct",
    "rstd": 6.336921931042771,
    "acc": 63.862295081967204,
    "cost": 1.0570491803278688
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Social Science",
    "model": "ichat",
    "rstd": 1.7452312314229743,
    "acc": 79.44350758853288,
    "cost": 1.1467116357504217
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 29.845655978714206,
    "acc": 32.08645787384208,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 17.388592029194776,
    "acc": 35.430083811204234,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 10.193331196851636,
    "acc": 50.299955888839875,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 13.241381242052546,
    "acc": 55.53153947948831,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 9.319120986360227,
    "acc": 38.69430966034407,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 8.89808326922299,
    "acc": 48.29730921923247,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 11.403013174438755,
    "acc": 59.83678870754301,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 15.880682752071035,
    "acc": 42.84075871195412,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 15.237014026638693,
    "acc": 49.585355094838995,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 17.34635075467415,
    "acc": 55.337450374944865,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 7.520850386022692,
    "acc": 44.76400529333922,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 9.153143767887066,
    "acc": 47.94441993824437,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 14.190501138292726,
    "acc": 53.63917071018968,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 11.777520298808058,
    "acc": 46.17556241729157,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 6.178046458203726,
    "acc": 51.755624172915745,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 12.517370285086619,
    "acc": 26.30348478164975,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 11.333317004578282,
    "acc": 49.219232465813846,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 20.70308222076699,
    "acc": 25.606528451698278,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 9.004084911393894,
    "acc": 47.569475077194525,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 6.5028120829448826,
    "acc": 75.28089887640449,
    "cost": 1.1396468699839486
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "llama-7b",
    "rstd": 28.788331674403178,
    "acc": 31.226290251433614,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "llama-13b",
    "rstd": 13.122353957986927,
    "acc": 42.205558006175565,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "llama-30b",
    "rstd": 11.364175979063324,
    "acc": 55.16541685046317,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "llama-65b",
    "rstd": 5.749256398706821,
    "acc": 60.974856638729605,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-7b-hf",
    "rstd": 11.880599136511663,
    "acc": 42.496691662990735,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-13b-hf",
    "rstd": 8.233284574982571,
    "acc": 52.16585796206441,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-70b-hf",
    "rstd": 4.980106057242382,
    "acc": 63.65681517423908,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 8.250247488788144,
    "acc": 43.27304808116453,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 5.9000698922903325,
    "acc": 51.46890163211292,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 5.226238924638475,
    "acc": 59.3868548742832,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.3",
    "rstd": 14.58619899904727,
    "acc": 43.427437141596826,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.3",
    "rstd": 9.763074707718014,
    "acc": 48.676665196294664,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.253496188135773,
    "acc": 56.72254080282312,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-7b-v1.5",
    "rstd": 9.294049435149086,
    "acc": 46.65637406263785,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "vicuna-13b-v1.5",
    "rstd": 7.5277439926627165,
    "acc": 52.84075871195413,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "falcon-7b",
    "rstd": 14.689256793399554,
    "acc": 26.224084693427436,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "falcon-40b",
    "rstd": 8.91371728920951,
    "acc": 51.605646228495814,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "falcon-7b-instruct",
    "rstd": 32.429609023718214,
    "acc": 25.941773268636968,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "falcon-40b-instruct",
    "rstd": 5.72733030987046,
    "acc": 50.273489192765766,
    "cost": 1.0383767093074547
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Humanities",
    "model": "ichat",
    "rstd": 2.4086468381340396,
    "acc": 76.9502407704655,
    "cost": 1.1396468699839486
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 14.954264296184212,
    "acc": 37.66042370279398,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 24.298672736592636,
    "acc": 33.50936444580903,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 7.663654895253214,
    "acc": 60.41756217377955,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 5.039662700283877,
    "acc": 64.56248081056188,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 9.474327364523841,
    "acc": 45.02916794596254,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 4.60759218208797,
    "acc": 58.76573533926927,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 4.945810552800181,
    "acc": 70.5004605465152,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 4.1738987317303735,
    "acc": 53.68130181148295,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 7.599793431461103,
    "acc": 60.87196806877493,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 6.2918762603211,
    "acc": 65.91955787534542,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 2.5832089905353706,
    "acc": 52.87688056493706,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 3.872659910264093,
    "acc": 57.07706478354314,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 6.7681476113856816,
    "acc": 64.10807491556648,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 3.3911628875911815,
    "acc": 56.334049739023634,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 1.4607243906713276,
    "acc": 61.78077985876573,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 9.082870782364926,
    "acc": 28.093337427080133,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 6.860305841249854,
    "acc": 59.760515812097026,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 12.235584009841721,
    "acc": 29.37672704943199,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 3.131661213887386,
    "acc": 61.23426466073073,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 3.6772733362103613,
    "acc": 71.00418410041841,
    "cost": 1.1213389121338913
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "llama-7b",
    "rstd": 16.79952171243861,
    "acc": 38.04728277556033,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "llama-13b",
    "rstd": 10.984151929163769,
    "acc": 53.632176849861835,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "llama-30b",
    "rstd": 8.05844211858487,
    "acc": 64.65459011360147,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "llama-65b",
    "rstd": 6.945091843314425,
    "acc": 67.62050967147681,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-7b-hf",
    "rstd": 8.115623396126981,
    "acc": 52.55756831439976,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-13b-hf",
    "rstd": 4.1569687376185716,
    "acc": 61.215842800122815,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-70b-hf",
    "rstd": 3.9044171818238356,
    "acc": 74.17869204789683,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.678010547849871,
    "acc": 53.48480196499846,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 3.864278041270373,
    "acc": 60.96407737181456,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 3.7070902948084856,
    "acc": 68.30825913417254,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-7b-v1.3",
    "rstd": 3.829341444650015,
    "acc": 53.10408351243475,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-13b-v1.3",
    "rstd": 6.282802234984431,
    "acc": 58.673626036229656,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-33b-v1.3",
    "rstd": 6.979785440726113,
    "acc": 64.48265274792755,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-7b-v1.5",
    "rstd": 5.303923268792378,
    "acc": 57.48848633712005,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "vicuna-13b-v1.5",
    "rstd": 5.38918992782943,
    "acc": 62.33957629720602,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "falcon-7b",
    "rstd": 12.236532164748457,
    "acc": 31.04083512434756,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "falcon-40b",
    "rstd": 3.4097666033553837,
    "acc": 63.91771568928461,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "falcon-7b-instruct",
    "rstd": 24.017048734131645,
    "acc": 31.046975744550203,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "falcon-40b-instruct",
    "rstd": 4.567370202296208,
    "acc": 62.032545287073994,
    "cost": 1.0534233957629722
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "Others",
    "model": "ichat",
    "rstd": 3.9718169593028647,
    "acc": 74.37935843793585,
    "cost": 1.1213389121338913
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 3.9391780905064033,
    "acc": 39.93458708094849,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 7.698785040867476,
    "acc": 51.43090760425184,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 3.858377491711323,
    "acc": 67.01553556827473,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 1.9755793676717968,
    "acc": 73.21340964840556,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 7.711500072064949,
    "acc": 45.658217497955846,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 4.982365898167521,
    "acc": 63.744889615699094,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 5.3088542777296555,
    "acc": 80.96484055600982,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 7.19466284930691,
    "acc": 57.54701553556828,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 8.552649151328268,
    "acc": 66.1488143908422,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 7.301934557385982,
    "acc": 78.26655764513491,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 4.171852917684925,
    "acc": 53.60588716271464,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 4.9278772034843215,
    "acc": 64.21913327882257,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 4.2681862341561025,
    "acc": 73.1152902698283,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 5.900032995757442,
    "acc": 59.133278822567455,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 3.6502341125567894,
    "acc": 69.94276369582994,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 4.014010997556524,
    "acc": 27.66966475878986,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 5.556761283964679,
    "acc": 63.85936222403924,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 10.031348817658957,
    "acc": 27.718724448078497,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 4.471354434476178,
    "acc": 63.793949304987734,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 0,
    "source_task": "arc",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 2.080188537676734,
    "acc": 84.43898443898443,
    "cost": 1.1425061425061425
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "llama-7b",
    "rstd": 4.559574816053332,
    "acc": 39.50940310711365,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "llama-13b",
    "rstd": 10.465862118496956,
    "acc": 56.45134914145543,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "llama-30b",
    "rstd": 3.4796538653836167,
    "acc": 73.60588716271464,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "llama-65b",
    "rstd": 4.029263331940426,
    "acc": 78.44644317252657,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-7b-hf",
    "rstd": 7.180518298513232,
    "acc": 57.367130008176616,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-13b-hf",
    "rstd": 4.892323845841946,
    "acc": 67.14636140637776,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-70b-hf",
    "rstd": 3.3074771331836303,
    "acc": 84.07195421095665,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-7b-chat-hf",
    "rstd": 5.783602464717157,
    "acc": 58.83892068683565,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-13b-chat-hf",
    "rstd": 4.925129577144604,
    "acc": 68.58544562551103,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "Llama-2-70b-chat-hf",
    "rstd": 4.214297084115388,
    "acc": 80.83401471790678,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-7b-v1.3",
    "rstd": 5.139747145701918,
    "acc": 57.28536385936222,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-13b-v1.3",
    "rstd": 5.542566373746721,
    "acc": 65.903515944399,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-33b-v1.3",
    "rstd": 3.3229615932789933,
    "acc": 74.9795584627964,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-7b-v1.5",
    "rstd": 7.48366198611714,
    "acc": 62.78004905968928,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "vicuna-13b-v1.5",
    "rstd": 4.772754560587903,
    "acc": 71.47996729354047,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "falcon-7b",
    "rstd": 10.435050627860923,
    "acc": 29.860997547015536,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "falcon-40b",
    "rstd": 1.6640685234061787,
    "acc": 69.32134096484056,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "falcon-7b-instruct",
    "rstd": 4.58989402118503,
    "acc": 29.337694194603433,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "falcon-40b-instruct",
    "rstd": 2.9474946927139447,
    "acc": 68.89615699100572,
    "cost": 1.14227309893704
  },
  {
    "num_shots": 5,
    "source_task": "arc",
    "target_task": "arc",
    "model": "ichat",
    "rstd": 1.9234187709751343,
    "acc": 86.76494676494676,
    "cost": 1.1425061425061425
  }
]