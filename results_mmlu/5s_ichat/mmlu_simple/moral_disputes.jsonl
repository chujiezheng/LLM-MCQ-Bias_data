{"type": "result", "data": {"idx": 1, "options": ["violates human dignity.", "fails a prima facie duty of honesty.", "is tantamount to asserting that you are infallible.", "is a risk worth taking of the speech is dangerous enough."], "observed": [[0.0, 0.03999999999996, 0.95999999999904, 0.0], [0.03999999999996, 0.93999999999906, 0.01999999999998, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.31999999999968, 0.0, 0.04999999999995, 0.62999999999937]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 9, "options": ["institutional adequacy", "dispersion of causes and effects", "fragmentation of agency", "all of the above"], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 12, "options": ["often have to be made quickly and without immediate authorization.", "should be made with visibility and accountability by the highest-level officials.", "have no objective answer.", "none of the above"], "observed": [[0.0999999999999, 0.8999999999991, 0.0, 0.0], [0.85999999999914, 0.0, 0.0, 0.13999999999986], [0.0, 0.0, 0.34999999999965, 0.64999999999935], [0.02999999999997, 0.08999999999991, 0.8799999999991199, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 13, "options": ["to minimize damage incurred by all individual living beings.", "to minimize the suffering of all sentient creatures.", "to promote the functional integrity of ecosystems.", "to promote human welfare."], "observed": [[0.0, 0.0, 0.72999999999927, 0.26999999999973], [0.0, 0.46999999999953, 0.52999999999947, 0.0], [0.10999999999988999, 0.6999999999993, 0.18999999999981, 0.0], [0.57999999999942, 0.0, 0.0, 0.41999999999958]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 24, "options": ["identical treatment.", "differential treatment.", "equal consideration.", "differential consideration."], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "B", "sampled": "C", "correct": false}}
{"type": "result", "data": {"idx": 25, "options": ["care ethics is an important development of virtue ethics.", "that traditional moral theories have difficulty explaining the rightness or wrongness of attitudes.", "that the only important more concepts are care and compassion.", "that we should think about welfare and happiness in terms of sympathy."], "observed": [[0.0999999999999, 0.8999999999991, 0.0, 0.0], [0.7999999999992, 0.0, 0.0, 0.1999999999998], [0.0, 0.0, 0.88999999999911, 0.10999999999988999], [0.10999999999988999, 0.73999999999926, 0.14999999999985, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 29, "options": ["Persons can never have a right to aid from anyone.", "The right to aid is a negative right.", "The consequences of helping the poor would be worse than the consequences of not helping them.", "This kind of right would require a contract or agreement, and the affluent haven't entered into a contract or agreement with the poor."], "observed": [[0.05999999999994, 0.03999999999996, 0.72999999999927, 0.16999999999983], [0.0, 0.75999999999924, 0.22999999999977, 0.00999999999999], [0.35999999999964, 0.56999999999943, 0.06999999999993, 0.0], [0.37999999999962, 0.0, 0.0, 0.6199999999993799]], "ideal": "D", "sampled": "C", "correct": false}}
{"type": "result", "data": {"idx": 31, "options": ["a distributionist.", "an abolitionist.", "a retentionist.", "a humanitarian."], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 33, "options": ["you have no obligation to let the violinist use your kidneys for that hour.", "the violinist has an obligation to disconnect him- or herself before that hour is over.", "because you ought to let the violinist use your kidneys for that hour, we should conclude that he or she has a right to use your kidneys for that hour.", "even though you ought to let the violinist use your kidneys for that hour, we should not conclude that he or she has a right to use your kidneys for that hour."], "observed": [[0.07999999999992, 0.0, 0.04999999999995, 0.86999999999913], [0.01999999999998, 0.00999999999999, 0.96999999999903, 0.0], [0.03999999999996, 0.9499999999990499, 0.00999999999999, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 38, "options": ["deliberately pro-creative.", "non-consensual.", "deliberately non-procreative.", "uncommonly practiced among adults."], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "B", "sampled": "C", "correct": false}}
{"type": "result", "data": {"idx": 39, "options": ["killing is in itself morally worse than letting die.", "letting die in itself is morally worse than killing.", "killing is not in itself morally worse than letting die.", "none of the above"], "observed": [[0.15999999999984, 0.0, 0.83999999999916, 0.0], [0.0, 0.98999999999901, 0.00999999999999, 0.0], [0.97999999999902, 0.0, 0.01999999999998, 0.0], [0.00999999999999, 0.4999999999995, 0.0, 0.48999999999951]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 46, "options": ["private clubs can rightfully exclude outsiders.", "the actions of groups can affect members outside that group.", "there is no difference between an individual's and a group's freedom of association.", "all of the above"], "observed": [[0.0, 0.999999999999, 0.0, 0.0], [0.98999999999901, 0.0, 0.00999999999999, 0.0], [0.0, 0.0, 0.01999999999998, 0.97999999999902], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 48, "options": ["a social leader's moral deliberations.", "an actual or hypothetical social agreement of some sort.", "a contract that has been signed by most of the affected parties.", "none of the above"], "observed": [[0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 53, "options": ["illicit cash flow to tax havens from rich countries exceeds aid to the world's poor.", "the implementation of neoliberal economic policies have had at mixed and at worse adverse impacts of the economic and social rights of the world's poor.", "that wealthy nations press their political and economic advantages to secure unfair trade agreements with poor countries.", "all of the above"], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 54, "options": ["sexual objectification is not always wrong.", "sexual objectification involves the total reduction of a person to an object.", "sexual objectification is not explainable in Kantian terms.", "sexual objectification involves the denial of a person's humanity."], "observed": [[0.33999999999966, 0.34999999999965, 0.0999999999999, 0.20999999999979], [0.34999999999965, 0.01999999999998, 0.53999999999946, 0.08999999999991], [0.00999999999999, 0.8799999999991199, 0.02999999999997, 0.07999999999992], [0.73999999999926, 0.02999999999997, 0.22999999999977, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 56, "options": ["jus ad bellum.", "antiwar pacifism.", "just war theory.", "moral nihilism."], "observed": [[0.0, 0.0, 0.11999999999988, 0.8799999999991199], [0.0, 0.0, 0.98999999999901, 0.00999999999999], [0.0, 0.83999999999916, 0.05999999999994, 0.0999999999999], [0.06999999999993, 0.22999999999977, 0.04999999999995, 0.64999999999935]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 58, "options": ["they help develop human capabilities.", "they minimize the amount of suffering in the world.", "they recognize, enforce, and implement duties not to violate human rights.", "they are universalizable."], "observed": [[0.84999999999915, 0.0, 0.14999999999985, 0.0], [0.0, 0.8799999999991199, 0.0, 0.11999999999988], [0.36999999999963, 0.0, 0.62999999999937, 0.0], [0.0, 0.93999999999906, 0.0, 0.05999999999994]], "ideal": "C", "sampled": "A", "correct": false}}
{"type": "result", "data": {"idx": 66, "options": ["just war theory.", "antiwar pacifism.", "moral nihilism.", "jus ad bellum."], "observed": [[0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 71, "options": ["It ignores the possibility that homosexuality is a lifestyle choice.", "It assumes that all innate desires are good ones.", "It is equivalent to recognizing that homosexuality is unusual.", "None of the above"], "observed": [[0.0, 0.93999999999906, 0.0, 0.05999999999994], [0.92999999999907, 0.0, 0.06999999999993, 0.0], [0.0, 0.03999999999996, 0.0, 0.95999999999904], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 75, "options": ["knowledge of how one is talented compared to others", "knowledge of one's social status", "knowledge of one's abilities, such as intelligence, strength, and so on", "none of the above"], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.98999999999901, 0.0, 0.0, 0.00999999999999]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 76, "options": ["excessive use of illegal drugs is the norm.", "moderate and/or controlled use of illegal drugs is the norm.", "an individual's illegal drug use inevitably diminishes over time.", "those who begin using illegal drugs typically do not stop until they become addicted."], "observed": [[0.0, 0.97999999999902, 0.0, 0.01999999999998], [0.95999999999904, 0.0, 0.03999999999996, 0.0], [0.0, 0.03999999999996, 0.0, 0.95999999999904], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 79, "options": ["the principle of maximizing happiness", "the principal principle", "the principle of double effect", "the principle of minimizing suffering"], "observed": [[0.0, 0.86999999999913, 0.0, 0.12999999999987], [0.56999999999943, 0.0, 0.42999999999957, 0.0], [0.0, 0.77999999999922, 0.17999999999982, 0.03999999999996], [0.73999999999926, 0.0, 0.25999999999974, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 80, "options": ["desirable as a rule.", "desirable in theory.", "desirable as a means.", "none of the above"], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.97999999999902, 0.0, 0.01999999999998, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 84, "options": ["all countries cooperating to change the existing incentive structure by introducing a system of enforceable sanctions to curb climate change.", "the agreement of more powerful nations to require less powerful nations to curb greenhouse gas emissions for the benefit of all humanity.", "the agreement of less powerful nations to boycott trade with more powerful nations until the latter agree to curb their greenhouse gas emissions.", "the agreement of a large number of individual agents to restrict their own pollution."], "observed": [[0.97999999999902, 0.0, 0.0, 0.01999999999998], [0.26999999999973, 0.0, 0.0, 0.72999999999927], [0.45999999999954, 0.0, 0.53999999999946, 0.0], [0.88999999999911, 0.10999999999988999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 88, "options": ["their use would lead to atheism or agnosticism.", "in using them, we would confuse our role in creation with God's role.", "the Bible explicitly opposes all forms of technological enhancement.", "all of the above"], "observed": [[0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 97, "options": ["genetic enhancement is always morally permissible.", "nature ought to be honored over personal choice.", "most people's conception of the varieties of goods is limited.", "we ought to always leave the development of valuable traits up to chance."], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 102, "options": ["we have an absolute right to freedom of association (i.e., one that cannot be outweighed by anything else).", "freedom of association implies that a legitimate state has a presumptive right to exclude anyone from its territory.", "immigration is harmful to low-income Americans.", "egalitarianism is a Marxist doctrine."], "observed": [[0.0999999999999, 0.8999999999991, 0.0, 0.0], [0.73999999999926, 0.00999999999999, 0.0, 0.24999999999975], [0.0, 0.0, 0.55999999999944, 0.43999999999955997], [0.0, 0.01999999999998, 0.97999999999902, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 104, "options": ["act-based deontology", "rule-based hedonism", "rule utilitarianism", "act utilitarianism"], "observed": [[0.0, 0.0, 0.01999999999998, 0.97999999999902], [0.0, 0.03999999999996, 0.95999999999904, 0.0], [0.08999999999991, 0.90999999999909, 0.0, 0.0], [0.23999999999976, 0.0, 0.0, 0.75999999999924]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 108, "options": ["hedonistic utilitarianism", "perfectionist consequentialism", "rule consequentialism", "By definition, consequentialist theories do not mention pain."], "observed": [[0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 114, "options": ["the wrongfulness of murder.", "that the death penalty is a better deterrent than life imprisonment.", "that criminals already face the risk of death.", "that criminals are usually undeterred by the chance of receiving the death penalty."], "observed": [[0.97999999999902, 0.0, 0.01999999999998, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 121, "options": ["it posits that all sex is rape.", "by suggesting that the harm of rape is that it is nonconsensual, it implies that all consensual sex is good.", "by suggesting that the harm of rape has nothing to do with the victim's gender, it implies that women are not especially harmed by nonconsensual sex.", "all of the above."], "observed": [[0.0, 0.84999999999915, 0.11999999999988, 0.02999999999997], [0.98999999999901, 0.00999999999999, 0.0, 0.0], [0.40999999999958997, 0.06999999999993, 0.03999999999996, 0.47999999999952], [0.02999999999997, 0.01999999999998, 0.93999999999906, 0.00999999999999]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 122, "options": ["individuals.", "societies.", "governments.", "families."], "observed": [[0.82999999999917, 0.14999999999985, 0.01999999999998, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.01999999999998, 0.96999999999903, 0.00999999999999, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 123, "options": ["voluntary euthanasia.", "physician-assisted suicide.", "passive euthanasia.", "active euthanasia."], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 126, "options": ["the abortion issue cannot be settled just by determining at what stage (if any) the fetus is a person.", "abortion is always morally permissible.", "abortion is never morally permissible.", "the abortion issue can be settled just by determining at what stage (if any) the fetus is a person."], "observed": [[0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.01999999999998, 0.97999999999902], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 127, "options": ["self-perfection.", "producing happiness.", "increasing welfare.", "self-sacrifice."], "observed": [[0.999999999999, 0.0, 0.0, 0.0], [0.01999999999998, 0.0, 0.00999999999999, 0.96999999999903], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 138, "options": ["Immanuel Kant", "Aristotle", "Jeremy Bentham", "John Stuart Mill"], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 140, "options": ["the ontological argument", "the argument from cosmology", "the argument from marginal cases", "none of the above"], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.97999999999902, 0.01999999999998, 0.0], [0.97999999999902, 0.01999999999998, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 141, "options": ["agreements made between individuals.", "pleasure and the absence of pain.", "facts about human nature.", "virtue."], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 144, "options": ["one's individual mindset and social setting.", "the pharmacological effects of drug use (e.g., withdrawal).", "one's genetic profile, which explains why some people have \"addictive personalities.\"", "specific psychological disorders such as obsessive-compulsive disorder."], "observed": [[0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 148, "options": ["overpopulation does not affect the number of people who are poor.", "overpopulation leads to creation of food banks that help curb poverty rates.", "world hunger and poverty leads to recognition of rights not to be hungry.", "the use of a world food bank to feed the hungry leads to an escalating series of emergency situations."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 151, "options": ["murderers of those who witness crimes.", "prostitutes who knowingly spread disease.", "people who knowingly buy stolen goods.", "all of the above"], "observed": [[0.0, 0.0, 0.24999999999975, 0.7499999999992499], [0.0, 0.31999999999968, 0.67999999999932, 0.0], [0.67999999999932, 0.31999999999968, 0.0, 0.0], [0.10999999999988999, 0.14999999999985, 0.27999999999972, 0.45999999999954]], "ideal": "C", "sampled": "D", "correct": false}}
{"type": "result", "data": {"idx": 152, "options": ["libertarian duties towards the global poor", "positive duties towards the global poor", "negative dutiestowards the global poor", "egalitarian duties towards the global poor."], "observed": [[0.0, 0.92999999999907, 0.05999999999994, 0.00999999999999], [0.999999999999, 0.0, 0.0, 0.0], [0.0999999999999, 0.0, 0.0, 0.8999999999991], [0.26999999999973, 0.0, 0.72999999999927, 0.0]], "ideal": "C", "sampled": "B", "correct": false}}
{"type": "result", "data": {"idx": 153, "options": ["It must be for an offense against legal rules.", "It must involve unpleasant consequences.", "It must not necessarily be of an actual or supposed offender.", "It must be intentionally administered by human beings other than the offender."], "observed": [[0.0, 0.33999999999966, 0.65999999999934, 0.0], [0.10999999999988999, 0.88999999999911, 0.0, 0.0], [0.18999999999981, 0.0, 0.0, 0.80999999999919], [0.04999999999995, 0.0, 0.56999999999943, 0.37999999999962]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 154, "options": ["God has deemed it desirable.", "experts on desirability have deemed it desirable.", "people do actually desire it.", "rational insight reveals it to be desirable."], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 157, "options": ["moral", "political", "cultural", "economic"], "observed": [[0.82999999999917, 0.16999999999983, 0.0, 0.0], [0.01999999999998, 0.0, 0.21999999999977998, 0.75999999999924], [0.0, 0.12999999999987, 0.8199999999991799, 0.04999999999995], [0.21999999999977998, 0.73999999999926, 0.03999999999996, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 159, "options": ["causing global warming.", "handing out too much foreign aid, which increases need.", "ignoring important aspects of their culture.", "indoctrinating them with Western values."], "observed": [[0.57999999999942, 0.0, 0.00999999999999, 0.40999999999958997], [0.01999999999998, 0.0, 0.41999999999958, 0.55999999999944], [0.00999999999999, 0.03999999999996, 0.92999999999907, 0.01999999999998], [0.00999999999999, 0.9499999999990499, 0.03999999999996, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 164, "options": ["a capacity for communal or friendly relationships", "a capacity for moral thought", "a capacity for rational deliberation", "a capacity for certain kinds of feelings or sentiments"], "observed": [[0.54999999999945, 0.01999999999998, 0.37999999999962, 0.04999999999995], [0.20999999999979, 0.35999999999964, 0.1999999999998, 0.22999999999977], [0.44999999999955, 0.14999999999985, 0.3999999999996, 0.0], [0.06999999999993, 0.1999999999998, 0.14999999999985, 0.57999999999942]], "ideal": "A", "sampled": "C", "correct": false}}
{"type": "result", "data": {"idx": 165, "options": ["dignity", "belonging to a moral community", "sentience", "none of the above"], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 166, "options": ["a list of crimes ranked according to their seriousness.", "a scale of punishments that correspond to the seriousness of certain crimes.", "treating criminals humanely.", "the death penalty for the most serious crimes."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.97999999999902, 0.01999999999998], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 169, "options": ["deontological approach", "Kantian approach", "virtue ethics approach", "consequentalist approach"], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 176, "options": ["we have a god-like control over the environment.", "we can measure in some way the incremental units of human satisfaction.", "nonhuman animals have no value whatsoever.", "all of the above"], "observed": [[0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.06999999999993, 0.0, 0.92999999999907], [0.00999999999999, 0.0, 0.98999999999901, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 178, "options": ["a description of an alleged actual equality among humans.", "a description of an alleged actual inequality among humans.", "a prescription of how we should treat nonhuman animals.", "a prescription of how we should treat humans."], "observed": [[0.0, 0.0, 0.35999999999964, 0.63999999999936], [0.0, 0.02999999999997, 0.72999999999927, 0.23999999999976], [0.8199999999991799, 0.17999999999982, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 179, "options": ["respect for the dignity of persons.", "the principle of equality.", "a consequentialist theory of punishment..", "equality retributivism."], "observed": [[0.999999999999, 0.0, 0.0, 0.0], [0.04999999999995, 0.0, 0.0, 0.9499999999990499], [0.03999999999996, 0.0, 0.95999999999904, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 182, "options": ["human life", "human procreation", "human sociability", "all of the above"], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.78999999999921, 0.20999999999979], [0.0, 0.82999999999917, 0.16999999999983, 0.0], [0.96999999999903, 0.02999999999997, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 187, "options": ["more harmful on average than legally permitted harmful activities.", "differing from the harms of other legally permitted harmful activities.", "more detrimental to a person's character than otherslegally permitted harmful activities.", "All of the above."], "observed": [[0.0, 0.08999999999991, 0.0, 0.90999999999909], [0.10999999999988999, 0.01999999999998, 0.84999999999915, 0.01999999999998], [0.0, 0.34999999999965, 0.0999999999999, 0.54999999999945], [0.10999999999988999, 0.16999999999983, 0.71999999999928, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 189, "options": ["reproduction rates.", "exploitation of other people.", "people having too many rights.", "none of the above"], "observed": [[0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 197, "options": ["God demands that all sexual activity occur in the context of marriage.", "this will ultimately produce the most happiness for the greatest number of persons.", "in marriage two persons equally and reciprocally transfer their whole person to the other.", "the universal law formulation of the categorical imperative requires that each of us be married."], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 201, "options": ["impersonal and categorical.", "merely a matter of the mother's preferences.", "a complex matter of the mother's personal integrity and her ideals about motherhood and creation.", "none of the above."], "observed": [[0.01999999999998, 0.0, 0.96999999999903, 0.00999999999999], [0.0, 0.97999999999902, 0.01999999999998, 0.0], [0.97999999999902, 0.01999999999998, 0.0, 0.0], [0.0, 0.04999999999995, 0.0, 0.9499999999990499]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 202, "options": ["it is anti-Christian.", "it would require a stronger system of taxation for the affluent.", "it would lead to a \"tragedy of the commons.\"", "all of the above"], "observed": [[0.0, 0.0, 0.9499999999990499, 0.04999999999995], [0.0, 0.8999999999991, 0.0999999999999, 0.0], [0.60999999999939, 0.38999999999961, 0.0, 0.0], [0.0, 0.0, 0.02999999999997, 0.96999999999903]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 206, "options": ["students to confabulate reasons.", "the pursuit of justice by marking out racism, sexism, and classism.", "labeling, by assigning global negative traits to persons.", "universities to bear overly burdensome legal obligations."], "observed": [[0.55999999999944, 0.04999999999995, 0.38999999999961, 0.0], [0.0, 0.88999999999911, 0.0, 0.10999999999988999], [0.5999999999994, 0.0, 0.3999999999996, 0.0], [0.0, 0.56999999999943, 0.01999999999998, 0.40999999999958997]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 209, "options": ["we make an effort to convince the terrorists that they are acting wrongly.", "we avoid harming terrorists to the same extent that we would avoid harming innocent civilians.", "we attack the lower-ranking terrorists first.", "we do not repeat the wrongs of terrorism in the process."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.9499999999990499, 0.0, 0.04999999999995], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 212, "options": ["the patient", "the patient's family", "the patient's caregiver", "legislators"], "observed": [[0.97999999999902, 0.0, 0.0, 0.01999999999998], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "C", "sampled": "A", "correct": false}}
{"type": "result", "data": {"idx": 213, "options": ["fatty foods and tobacco products are not actually harmful.", "there is nothing wrong with limiting people's access to products that are harmful to them.", "the benefits of prohibiting these products would not outweigh the costs.", "all of the above"], "observed": [[0.0, 0.56999999999943, 0.37999999999962, 0.04999999999995], [0.02999999999997, 0.92999999999907, 0.03999999999996, 0.0], [0.51999999999948, 0.42999999999957, 0.0, 0.04999999999995], [0.02999999999997, 0.0, 0.93999999999906, 0.02999999999997]], "ideal": "B", "sampled": "C", "correct": false}}
{"type": "result", "data": {"idx": 215, "options": ["the animal's direct moral standing.", "the animals capacity for suffering.", "the bad qualities of character that our actions evince.", "none of the above"], "observed": [[0.05999999999994, 0.92999999999907, 0.00999999999999, 0.0], [0.8799999999991199, 0.0, 0.00999999999999, 0.10999999999988999], [0.0, 0.0, 0.08999999999991, 0.90999999999909], [0.0, 0.00999999999999, 0.98999999999901, 0.0]], "ideal": "C", "sampled": "B", "correct": false}}
{"type": "result", "data": {"idx": 216, "options": ["the patient's opportunities for self-determination", "the patient's capacity for self-determination", "the ability to provide the patient with options", "the ability to share reasons with the patient"], "observed": [[0.98999999999901, 0.00999999999999, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 224, "options": ["unequal social order.", "authoritarian regimes.", "crime.", "pollution."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 225, "options": ["produce and raise a child.", "go down a slippery slope.", "treat disease.", "none of the above"], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 228, "options": ["honesty", "courage", "kindness", "all of the above"], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 231, "options": ["justifying one instance of torture requires justifying the practice of torture.", "it is virtually impossible for torture to be limited to just one instance.", "both A and B", "neither A nor B"], "observed": [[0.10999999999988999, 0.0, 0.88999999999911, 0.0], [0.0, 0.6199999999993799, 0.0, 0.37999999999962], [0.01999999999998, 0.0, 0.97999999999902, 0.0], [0.0, 0.32999999999967, 0.02999999999997, 0.63999999999936]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 236, "options": ["the punishment would likely produce as much overall intrinsic value as would any other alternative punishment.", "the punishment is consistent with treating the person as an end in him- or herself.", "the punishment is proportional to the wrongness of the crime.", "all of the above"], "observed": [[0.90999999999909, 0.0, 0.0, 0.08999999999991], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.7999999999992, 0.1999999999998, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 237, "options": ["\"Every whole is greater than its part.\"", "\"The light of Thy countenance, O Lord, is signed upon us.\"", "\"Things equal to one and the same are equal to one another.\"", "\"Man is a rational being.\""], "observed": [[0.02999999999997, 0.82999999999917, 0.0, 0.13999999999986], [0.95999999999904, 0.0, 0.02999999999997, 0.00999999999999], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 238, "options": ["showing that a fetus is a person with full moral rights, including the right to life.", "appealing to the fact that a fetus is biologically human and arguing that it is presumptively morally wrong to kill biologically human beings.", "showing that a fetus is sentient and that it is morally wrong to harm and kill sentient creatures.", "none of the above"], "observed": [[0.0, 0.08999999999991, 0.7999999999992, 0.10999999999988999], [0.35999999999964, 0.08999999999991, 0.54999999999945, 0.0], [0.0, 0.0, 0.01999999999998, 0.97999999999902], [0.0, 0.02999999999997, 0.04999999999995, 0.91999999999908]], "ideal": "D", "sampled": "C", "correct": false}}
{"type": "result", "data": {"idx": 241, "options": ["absolutely wrong.", "seriously presumptively wrong.", "generally permissible.", "always permissible."], "observed": [[0.0, 0.999999999999, 0.0, 0.0], [0.97999999999902, 0.01999999999998, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 243, "options": ["a war simpliciter.", "a hot war.", "a cold war.", "none of the above"], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 245, "options": ["Terrorism is a form of freedom of speech.", "Terrorism is a last resort.", "Terrorism benefits oppressed groups.", "All political activity is terroristic."], "observed": [[0.07999999999992, 0.0, 0.14999999999985, 0.76999999999923], [0.0, 0.0, 0.85999999999914, 0.13999999999986], [0.06999999999993, 0.43999999999955997, 0.48999999999951, 0.0], [0.14999999999985, 0.82999999999917, 0.0, 0.01999999999998]], "ideal": "A", "sampled": "D", "correct": false}}
{"type": "result", "data": {"idx": 246, "options": ["anti-egalitarianism is compatible with liberal cosmopolitanism.", "closing borders to all potential immigrations is an inherently racist social policy.", "nation-states have an obligation to open their borders to the least well-off potential immigrants.", "nation-states have a presumptive right to close their borders to all potential immigrants."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.98999999999901, 0.0, 0.0, 0.00999999999999]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 264, "options": ["The argument assumes genetic determinism or genetic reductionism.", "The expectations people will place on SCNT individuals could be no worse than normal expectations of children created sexually.", "People's prejudicial attitudes are likely to change.", "If people's prejudicial attitudes do not change, then we should not allow SCNT."], "observed": [[0.0, 0.10999999999988999, 0.13999999999986, 0.7499999999992499], [0.0999999999999, 0.01999999999998, 0.8799999999991199, 0.0], [0.0999999999999, 0.88999999999911, 0.0, 0.00999999999999], [0.23999999999976, 0.0, 0.02999999999997, 0.72999999999927]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 265, "options": ["that action's relationship to the operative rules of law.", "the logical consistency behind the motive of actions of the same type.", "whether a virtuous person would endorse a rule requiring, permitting, or prohibiting that action.", "whether that action is required, permitted, or prohibited by a rule the consequences of which are best."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 270, "options": ["the female who carries the zygote to term.", "the individual who donates the nucleus.", "the female who donates the egg.", "none of the above"], "observed": [[0.0, 0.8999999999991, 0.0, 0.0999999999999], [0.88999999999911, 0.0, 0.10999999999988999, 0.0], [0.0, 0.07999999999992, 0.0, 0.91999999999908], [0.0, 0.0, 0.97999999999902, 0.01999999999998]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 273, "options": ["a causal consequence of hate speech.", "a harm that derives from the kind of attitude expressed in the act of hate speech.", "both A and B", "neither A nor B"], "observed": [[0.0, 0.32999999999967, 0.66999999999933, 0.0], [0.8199999999991799, 0.17999999999982, 0.0, 0.0], [0.00999999999999, 0.0, 0.0, 0.98999999999901], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "A", "sampled": "B", "correct": false}}
{"type": "result", "data": {"idx": 277, "options": ["A is a better athlete.", "B is a better athlete.", "B doesn't count as an athlete because training precludes athleticism.", "A and B are equally good athletes."], "observed": [[0.04999999999995, 0.7499999999992499, 0.0, 0.1999999999998], [0.21999999999977998, 0.0, 0.67999999999932, 0.0999999999999], [0.0, 0.27999999999972, 0.43999999999955997, 0.27999999999972], [0.13999999999986, 0.1999999999998, 0.65999999999934, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 281, "options": ["She or her children are economically dependent on her male partner, and so she reasons that she better have sex with him and keep him happy.", "Her refusal will result in her partner's being in a foul mood which is more burdensome than having undesired sex.", "Her refusal might result in a violent outburst.", "All of the above."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.93999999999906, 0.05999999999994, 0.0], [0.98999999999901, 0.00999999999999, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 284, "options": ["The problems associated with how we should use our natural environment ultimately concern how human beings should treat each other.", "We should think in terms of \"the balance of nature\" to properly appreciate the value of the natural environment.", "The problems associated with how we should use our natural environment are not merely economic problems.", "We should ignore all economic motives in deciding questions about land use."], "observed": [[0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.8799999999991199, 0.0, 0.11999999999988], [0.8999999999991, 0.0, 0.0999999999999, 0.0], [0.0, 0.15999999999984, 0.0, 0.83999999999916]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 291, "options": ["rights of noninterference.", "rights to goods and services.", "both A and B", "neither A nor B"], "observed": [[0.7499999999992499, 0.0, 0.00999999999999, 0.23999999999976], [0.0, 0.0, 0.00999999999999, 0.98999999999901], [0.0999999999999, 0.00999999999999, 0.88999999999911, 0.0], [0.21999999999977998, 0.75999999999924, 0.0, 0.01999999999998]], "ideal": "C", "sampled": "A", "correct": false}}
{"type": "result", "data": {"idx": 297, "options": ["They use a drug to relieve a craving.", "They use a drug even though they obviously shouldn't.", "Although they believe they should use the drug when they decide to use it, at other times they believe they should not use the drug anymore.", "all of the above"], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.03999999999996, 0.95999999999904, 0.0], [0.0, 0.97999999999902, 0.01999999999998, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 299, "options": ["John's duty to return to Mary that car that he borrowed from her", "John's duty to allow Mary to pursue goals that she values", "John's duty to not harm Mary", "John's duty to not commit suicide"], "observed": [[0.18999999999981, 0.80999999999919, 0.0, 0.0], [0.00999999999999, 0.0, 0.0, 0.98999999999901], [0.0, 0.0, 0.97999999999902, 0.01999999999998], [0.0, 0.67999999999932, 0.31999999999968, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 301, "options": ["The envisioned results of the action or practice under consideration turn out not to be bad.", "The central idea of the argument-that the action or practice under consideration will lead us down a path to disaster-turns out not to be plausible.", "both A and B are correct; either condition would make the argument fallacious.", "neither A nor B is correct; neither condition would make the argument fallacious."], "observed": [[0.0, 0.0, 0.98999999999901, 0.00999999999999], [0.03999999999996, 0.95999999999904, 0.0, 0.0], [0.76999999999923, 0.11999999999988, 0.0, 0.10999999999988999], [0.02999999999997, 0.02999999999997, 0.76999999999923, 0.16999999999983]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 306, "options": ["virtue.", "beauty.", "praiseworthiness.", "dignity."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 308, "options": ["masturbate.", "engage in prostitution.", "engage in consensual sexual activity outside of marriage.", "None of the above."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 311, "options": ["the importance of attitudes as well as actions.", "the concepts of care and compassion.", "relationships as fundamental to one's identity and as a source of moral obligation.", "all of the above."], "observed": [[0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0]], "ideal": "D", "sampled": "D", "correct": true}}
{"type": "result", "data": {"idx": 313, "options": ["Mary's upbringing.", "an action Mary performed.", "Mary's moral character.", "what John thinks he would have done."], "observed": [[0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 314, "options": ["exclude", "punish", "advocate", "none of the above"], "observed": [[0.98999999999901, 0.0, 0.0, 0.00999999999999], [0.0, 0.0, 0.01999999999998, 0.97999999999902], [0.14999999999985, 0.06999999999993, 0.77999999999922, 0.0], [0.0999999999999, 0.8999999999991, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 323, "options": ["freedom of speech", "freedom of the press", "right to bear arms", "right to privacy"], "observed": [[0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "B", "sampled": "A", "correct": false}}
{"type": "result", "data": {"idx": 328, "options": ["they cannot reproduce.", "they do not have a human genetic profile.", "they are genetically and functionally identifiable as parts of the male or female potential parents.", "all of the above"], "observed": [[0.0, 0.0, 0.82999999999917, 0.16999999999983], [0.0, 0.78999999999921, 0.20999999999979, 0.0], [0.52999999999947, 0.43999999999955997, 0.0, 0.02999999999997], [0.02999999999997, 0.00999999999999, 0.08999999999991, 0.86999999999913]], "ideal": "C", "sampled": "C", "correct": true}}
{"type": "result", "data": {"idx": 334, "options": ["emotional reasoning.", "critical reasoning.", "reflective reasoning.", "all of the above."], "observed": [[0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "B", "sampled": "A", "correct": false}}
{"type": "result", "data": {"idx": 337, "options": ["being at least six feet tall (in a population where this is above average)", "having an IQ of at least 150 (in a population where this is the average)", "being at least six feet tall (in a population where this is the average)", "all of the above"], "observed": [[0.83999999999916, 0.0, 0.07999999999992, 0.07999999999992], [0.0, 0.08999999999991, 0.0, 0.90999999999909], [0.18999999999981, 0.05999999999994, 0.7499999999992499, 0.0], [0.00999999999999, 0.7999999999992, 0.02999999999997, 0.15999999999984]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 338, "options": ["consequentialism.", "natural law theory.", "rights-based theory.", "virtue ethics."], "observed": [[0.0, 0.999999999999, 0.0, 0.0], [0.999999999999, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 339, "options": ["miscarriages of justice are offset by the moral benefits and usefulness of doing justice.", "there have been no miscarriages of justice, in the sense used in the objection.", "miscarriages of justice are inevitable and so irrelevant.", "none of the above"], "observed": [[0.84999999999915, 0.0, 0.0, 0.14999999999985], [0.0, 0.0, 0.0, 0.999999999999], [0.0, 0.0, 0.999999999999, 0.0], [0.0, 0.999999999999, 0.0, 0.0]], "ideal": "A", "sampled": "A", "correct": true}}
{"type": "result", "data": {"idx": 340, "options": ["If a practice is riskier than the alternatives, then that practice is moral, prudent, or otherwise to be pursued.", "If a practice is risker than the alternatives, then that practice is immoral, imprudent, or otherwise to be avoided.", "If a practice is safer than the alternatives, then that practice is immoral, imprudent, or otherwise to be avoided.", "none of the above"], "observed": [[0.08999999999991, 0.56999999999943, 0.30999999999968997, 0.02999999999997], [0.76999999999923, 0.14999999999985, 0.03999999999996, 0.03999999999996], [0.14999999999985, 0.10999999999988999, 0.0999999999999, 0.63999999999936], [0.0, 0.14999999999985, 0.7499999999992499, 0.0999999999999]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "result", "data": {"idx": 342, "options": ["only violence", "violence and oppression in the form of subordination, exploitation, and cultural imperialism.", "only forms of oppression like subordination, exploitation, and cultural imperialism.", "none of the above"], "observed": [[0.0, 0.90999999999909, 0.08999999999991, 0.0], [0.95999999999904, 0.0, 0.03999999999996, 0.0], [0.00999999999999, 0.00999999999999, 0.0, 0.97999999999902], [0.0, 0.0, 0.999999999999, 0.0]], "ideal": "B", "sampled": "B", "correct": true}}
{"type": "metric", "data": {"accuracy": 0.84, "boostrap_std": 0.037918459884336016}}
